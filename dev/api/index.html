<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API Reference · ADCME</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="ADCME logo"/></a><div class="docs-package-name"><span class="docs-autofit">ADCME</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><a class="tocitem" href="../inverse_modeling/">Inverse Modeling</a></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../array/">Tensor Operations</a></li><li><a class="tocitem" href="../sparse/">Sparse Linear Algebra</a></li><li><a class="tocitem" href="../newton_raphson/">Newton Raphson</a></li><li><a class="tocitem" href="../parallel/">Parallel Computing</a></li><li><a class="tocitem" href="../ode/">PDE/ODE Solvers</a></li></ul></li><li><span class="tocitem">Resources</span><ul><li><a class="tocitem" href="../customop/">Custom Operators</a></li><li><a class="tocitem" href="../while_loop/">While Loops</a></li><li><a class="tocitem" href="../julia_customop/">Julia Custom Operators</a></li><li><a class="tocitem" href="../pytorchnn/">Neural Network in C++</a></li><li><a class="tocitem" href="../extra/">Miscellaneous Tools</a></li><li><a class="tocitem" href="../ot/">Optimal Transport</a></li></ul></li><li><span class="tocitem">Applications</span><ul><li><a class="tocitem" href="../apps_ana/">Adversarial Numerical Analysis</a></li><li><a class="tocitem" href="../apps_levy/">Calibrating Multivariate Lévy Processes with Neural Networks</a></li><li><a class="tocitem" href="../apps_constitutive_law/">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></li></ul></li><li class="is-active"><a class="tocitem" href>API Reference</a><ul class="internal"><li><a class="tocitem" href="#Core-Functions-1"><span>Core Functions</span></a></li><li><a class="tocitem" href="#Variables-1"><span>Variables</span></a></li><li><a class="tocitem" href="#Random-Variables-1"><span>Random Variables</span></a></li><li><a class="tocitem" href="#Sparse-Matrix-1"><span>Sparse Matrix</span></a></li><li><a class="tocitem" href="#Operations-1"><span>Operations</span></a></li><li><a class="tocitem" href="#IO-1"><span>IO</span></a></li><li><a class="tocitem" href="#Optimization-1"><span>Optimization</span></a></li><li><a class="tocitem" href="#Neural-Networks-1"><span>Neural Networks</span></a></li><li><a class="tocitem" href="#Generative-Neural-Nets-1"><span>Generative Neural Nets</span></a></li><li><a class="tocitem" href="#Tools-1"><span>Tools</span></a></li><li><a class="tocitem" href="#Datasets-1"><span>Datasets</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="API-Reference-1"><a class="docs-heading-anchor" href="#API-Reference-1">API Reference</a><a class="docs-heading-anchor-permalink" href="#API-Reference-1" title="Permalink"></a></h1><h2 id="Core-Functions-1"><a class="docs-heading-anchor" href="#Core-Functions-1">Core Functions</a><a class="docs-heading-anchor-permalink" href="#Core-Functions-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.add_collection-Tuple{String,PyObject}" href="#ADCME.add_collection-Tuple{String,PyObject}"><code>ADCME.add_collection</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">add_collection(name::String, v::PyObject)</code></pre><p>Adds <code>v</code> to the collection with name <code>name</code>. If <code>name</code> does not exist, a new one is created.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/core.jl#L38-L42">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.add_collection-Tuple{String,Vararg{PyObject,N} where N}" href="#ADCME.add_collection-Tuple{String,Vararg{PyObject,N} where N}"><code>ADCME.add_collection</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">add_collection(name::String, vs::PyObject...)</code></pre><p>Adds operators <code>vs</code> to the collection with name <code>name</code>. If <code>name</code> does not exist, a new one is created.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/core.jl#L48-L52">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_collection" href="#ADCME.get_collection"><code>ADCME.get_collection</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_collection(name::Union{String, Missing})</code></pre><p>Returns the collection with name <code>name</code>. If <code>name</code> is <code>missing</code>, returns all the trainable variables.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/core.jl#L24-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.has_gpu-Tuple{}" href="#ADCME.has_gpu-Tuple{}"><code>ADCME.has_gpu</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">has_gpu()</code></pre><p>Checks if GPU is available.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>ADCME will use GPU automatically if GPU is available. To disable GPU, set the environment variable <code>ENV[&quot;CUDA_VISIBLE_DEVICES&quot;]=&quot;&quot;</code> before importing ADCME </p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/core.jl#L182-L189">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.if_else-Tuple{Union{Bool, PyObject, Array},Any,Any,Vararg{Any,N} where N}" href="#ADCME.if_else-Tuple{Union{Bool, PyObject, Array},Any,Any,Vararg{Any,N} where N}"><code>ADCME.if_else</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">if_else(condition::Union{PyObject,Array,Bool}, fn1, fn2, args...;kwargs...)</code></pre><ul><li>If <code>condition</code> is a scalar boolean, it outputs <code>fn1</code> or <code>fn2</code> (a function with no input argument or a tensor) based on whether <code>condition</code> is true or false.</li><li>If <code>condition</code> is a boolean array, if returns <code>condition .* fn1 + (1 - condition) .* fn2</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/core.jl#L165-L170">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.reset_default_graph-Tuple{}" href="#ADCME.reset_default_graph-Tuple{}"><code>ADCME.reset_default_graph</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">reset_default_graph()</code></pre><p>Resets the graph by removing all the operators. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/core.jl#L18-L22">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.stop_gradient-Tuple{PyObject,Vararg{Any,N} where N}" href="#ADCME.stop_gradient-Tuple{PyObject,Vararg{Any,N} where N}"><code>ADCME.stop_gradient</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">stop_gradient(o::PyObject, args...;kwargs...)</code></pre><p>Disconnects <code>o</code> from gradients backpropagation. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/core.jl#L200-L205">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.tensor-Tuple{String}" href="#ADCME.tensor-Tuple{String}"><code>ADCME.tensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tensor(s::String)</code></pre><p>Returns the tensor with name <code>s</code>. See <a href="#ADCME.tensorname-Tuple{PyObject}"><code>tensorname</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/core.jl#L60-L64">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.tensorname-Tuple{PyObject}" href="#ADCME.tensorname-Tuple{PyObject}"><code>ADCME.tensorname</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tensorname(o::PyObject)</code></pre><p>Returns the name of the tensor. See <a href="#ADCME.tensor-Tuple{String}"><code>tensor</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/core.jl#L69-L73">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.run_profile-Tuple" href="#ADCME.run_profile-Tuple"><code>ADCME.run_profile</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">run_profile(args...;kwargs...)</code></pre><p>Runs the session with tracing information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/run.jl#L32-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.save_profile" href="#ADCME.save_profile"><code>ADCME.save_profile</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">save_profile(filename::String=&quot;default_timeline.json&quot;)</code></pre><p>Save the timeline information to file <code>filename</code>. </p><ul><li>Open Chrome and navigate to chrome://tracing</li><li>Load the timeline file</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/run.jl#L44-L50">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.bind-Tuple{PyObject,Vararg{Any,N} where N}" href="#Base.bind-Tuple{PyObject,Vararg{Any,N} where N}"><code>Base.bind</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">bind(op::PyObject, ops...)</code></pre><p>Adding operations <code>ops</code> to the dependencies of <code>op</code>. The function is useful when we want to execute <code>ops</code> but <code>ops</code> is not  in the dependency of the final output. For example, if we want to print <code>i</code> each time <code>i</code> is evaluated</p><pre><code class="language-julia">i = constant(1.0)
op = tf.print(i)
i = bind(i, op)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/core.jl#L111-L121">source</a></section></article><h2 id="Variables-1"><a class="docs-heading-anchor" href="#Variables-1">Variables</a><a class="docs-heading-anchor-permalink" href="#Variables-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.TensorArray" href="#ADCME.TensorArray"><code>ADCME.TensorArray</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">TensorArray(size_::Int64=0, args...;kwargs...)</code></pre><p>Constructs a tensor array for <a href="@ref"><code>while_loop</code></a>.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/variable.jl#L451-L455">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.Variable-Tuple{Any}" href="#ADCME.Variable-Tuple{Any}"><code>ADCME.Variable</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Variable(initial_value;kwargs...)</code></pre><p>Constructs a ref tensor from <code>value</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/variable.jl#L44-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.cell-Tuple{Array,Vararg{Any,N} where N}" href="#ADCME.cell-Tuple{Array,Vararg{Any,N} where N}"><code>ADCME.cell</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cell(arr::Array, args...;kwargs...)</code></pre><p>Construct a cell tensor. </p><p><strong>Example</strong></p><pre><code class="language-julia-REPL">julia&gt; r = cell([[1.],[2.,3.]])
julia&gt; run(sess, r[1])
1-element Array{Float32,1}:
 1.0
julia&gt; run(sess, r[2])
2-element Array{Float32,1}:
 2.0
 3.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/variable.jl#L57-L72">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.constant-Tuple{Any}" href="#ADCME.constant-Tuple{Any}"><code>ADCME.constant</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">constant(value; kwargs...)</code></pre><p>Constructs a non-trainable tensor from <code>value</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/variable.jl#L28-L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.convert_to_tensor-Union{Tuple{Union{Missing, Nothing, Number, PyObject, Array{T,N} where N}}, Tuple{T}} where T&lt;:Number" href="#ADCME.convert_to_tensor-Union{Tuple{Union{Missing, Nothing, Number, PyObject, Array{T,N} where N}}, Tuple{T}} where T&lt;:Number"><code>ADCME.convert_to_tensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">convert_to_tensor(o::Union{PyObject, Number, Array{T}, Missing, Nothing}; dtype::Union{Type, Missing}=missing) where T&lt;:Number</code></pre><p>Converts the input <code>o</code> to tensor. If <code>o</code> is already a tensor and <code>dtype</code> (if provided) is the same as that of <code>o</code>, the operator does nothing. Otherwise, <code>convert_to_tensor</code> converts the numerical array to a constant tensor or casts the data type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/variable.jl#L489-L494">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.gradient_checkpointing" href="#ADCME.gradient_checkpointing"><code>ADCME.gradient_checkpointing</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gradient_checkpointing(type::String=&quot;speed&quot;)</code></pre><p>Uses checkpointing scheme for gradients. </p><ul><li>&#39;speed&#39;:  checkpoint all outputs of convolutions and matmuls. these ops are usually the most expensive,   so checkpointing them maximizes the running speed   (this is a good option if nonlinearities, concats, batchnorms, etc are taking up a lot of memory)</li><li>&#39;memory&#39;: try to minimize the memory usage   (currently using a very simple strategy that identifies a number of bottleneck tensors in the graph to checkpoint)</li><li>&#39;collection&#39;: look for a tensorflow collection named &#39;checkpoints&#39;, which holds the tensors to checkpoint</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/variable.jl#L515-L525">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.gradients-Tuple{PyObject,PyObject}" href="#ADCME.gradients-Tuple{PyObject,PyObject}"><code>ADCME.gradients</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">gradients(ys::PyObject, xs::PyObject; kwargs...)</code></pre><p>Computes the gradients of <code>ys</code> w.r.t <code>xs</code>. </p><ul><li>If <code>ys</code> is a scalar, <code>gradients</code> returns the gradients with the same shape as <code>xs</code>.</li><li>If <code>ys</code> is a vector, <code>gradients</code> returns the Jacobian <span>$\frac{\partial y}{\partial x}$</span></li></ul><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The second usage is not suggested since <code>ADCME</code> adopts reverse mode automatic differentiation.  Although in the case <code>ys</code> is a vector and <code>xs</code> is a scalar, <code>gradients</code> cleverly uses forward mode automatic differentiation, it requires that the second order gradients are implemented for relevant operators. </p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/variable.jl#L161-L173">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.hessian-Tuple{PyObject,PyObject}" href="#ADCME.hessian-Tuple{PyObject,PyObject}"><code>ADCME.hessian</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>hessian</code> computes the hessian of a scalar function f with respect to vector inputs xs</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/variable.jl#L271-L273">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.tensor-Union{Tuple{Array{T,1}}, Tuple{T}} where T" href="#ADCME.tensor-Union{Tuple{Array{T,1}}, Tuple{T}} where T"><code>ADCME.tensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tensor(v::Array{T,2}; dtype=Float64, sparse=false) where T</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/variable.jl#L401-L403">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.tensor-Union{Tuple{Array{T,2}}, Tuple{T}} where T" href="#ADCME.tensor-Union{Tuple{Array{T,2}}, Tuple{T}} where T"><code>ADCME.tensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tensor(v::Array{T,2}; dtype=Float64, sparse=false) where T</code></pre><p>Convert a generic array <code>v</code> to a tensor. For example, </p><pre><code class="language-julia">v = [0.0 constant(1.0) 2.0
    constant(2.0) 0.0 1.0]
u = tensor(v)</code></pre><p><code>u</code> will be a <span>$2\times 3$</span> tensor. </p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>This function is expensive. Use with caution.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/variable.jl#L420-L432">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.read-Tuple{PyObject,Union{Integer, PyObject}}" href="#Base.read-Tuple{PyObject,Union{Integer, PyObject}}"><code>Base.read</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">read(ta::PyObject, i::Union{PyObject,Integer})</code></pre><p>Reads data from <a href="#ADCME.TensorArray"><code>TensorArray</code></a> at index <code>i</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/variable.jl#L471-L476">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.write-Tuple{PyObject,Union{Integer, PyObject},PyObject}" href="#Base.write-Tuple{PyObject,Union{Integer, PyObject},PyObject}"><code>Base.write</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">write(ta::PyObject, i::Union{PyObject,Integer}, obj)</code></pre><p>Writes data <code>obj</code> to <a href="#ADCME.TensorArray"><code>TensorArray</code></a> at index <code>i</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/variable.jl#L480-L485">source</a></section></article><h2 id="Random-Variables-1"><a class="docs-heading-anchor" href="#Random-Variables-1">Random Variables</a><a class="docs-heading-anchor-permalink" href="#Random-Variables-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.categorical-Tuple{Union{Integer, PyObject}}" href="#ADCME.categorical-Tuple{Union{Integer, PyObject}}"><code>ADCME.categorical</code></a> — <span class="docstring-category">Method</span></header><section><div><p>categorical(n::Union{PyObject, Integer}; kwargs...)</p><p><code>kwargs</code> has a keyword argument <code>logits</code>, a 2-D Tensor with shape <code>[batch_size, num_classes]</code>.   Each slice <code>[i, :]</code> represents the unnormalized log-probabilities for all classes.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/random.jl#L16-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.choice-Tuple{Union{PyObject, Array},Union{Integer, PyObject}}" href="#ADCME.choice-Tuple{Union{PyObject, Array},Union{Integer, PyObject}}"><code>ADCME.choice</code></a> — <span class="docstring-category">Method</span></header><section><div><p>choice(inputs::Union{PyObject, Array}, n_samples::Union{PyObject, Integer};replace::Bool=false)</p><p>Choose <code>n_samples</code> samples from <code>inputs</code> with/without replacement. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/random.jl#L41-L45">source</a></section></article><h2 id="Sparse-Matrix-1"><a class="docs-heading-anchor" href="#Sparse-Matrix-1">Sparse Matrix</a><a class="docs-heading-anchor-permalink" href="#Sparse-Matrix-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.SparseTensor-Tuple{SparseArrays.SparseMatrixCSC}" href="#ADCME.SparseTensor-Tuple{SparseArrays.SparseMatrixCSC}"><code>ADCME.SparseTensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">SparseTensor(A::SparseMatrixCSC)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/sparse.jl#L80-L82">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.SparseTensor-Union{Tuple{S}, Tuple{T}, Tuple{Union{Array{T,1}, PyObject},Union{Array{T,1}, PyObject},Union{Array{Float64,1}, PyObject}}, Tuple{Union{Array{T,1}, PyObject},Union{Array{T,1}, PyObject},Union{Array{Float64,1}, PyObject},Union{Nothing, PyObject, S}}, Tuple{Union{Array{T,1}, PyObject},Union{Array{T,1}, PyObject},Union{Array{Float64,1}, PyObject},Union{Nothing, PyObject, S},Union{Nothing, PyObject, S}}} where S&lt;:Integer where T&lt;:Integer" href="#ADCME.SparseTensor-Union{Tuple{S}, Tuple{T}, Tuple{Union{Array{T,1}, PyObject},Union{Array{T,1}, PyObject},Union{Array{Float64,1}, PyObject}}, Tuple{Union{Array{T,1}, PyObject},Union{Array{T,1}, PyObject},Union{Array{Float64,1}, PyObject},Union{Nothing, PyObject, S}}, Tuple{Union{Array{T,1}, PyObject},Union{Array{T,1}, PyObject},Union{Array{Float64,1}, PyObject},Union{Nothing, PyObject, S},Union{Nothing, PyObject, S}}} where S&lt;:Integer where T&lt;:Integer"><code>ADCME.SparseTensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">SparseTensor(I::Union{PyObject,Array{T,1}}, J::Union{PyObject,Array{T,1}}, V::Union{Array{Float64,1}, PyObject}, m::Union{S, PyObject, Nothing}=nothing, n::Union{S, PyObject, Nothing}=nothing) where {T&lt;:Integer, S&lt;:Integer}</code></pre><p>Constructs a sparse tensor.  Examples:</p><pre><code class="language-none">ii = [1;2;3;4]
jj = [1;2;3;4]
vv = [1.0;1.0;1.0;1.0]
s = SparseTensor(ii, jj, vv, 4, 4)
s = SparseTensor(sprand(10,10,0.3))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/sparse.jl#L12-L24">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.SparseAssembler-Tuple{}" href="#ADCME.SparseAssembler-Tuple{}"><code>ADCME.SparseAssembler</code></a> — <span class="docstring-category">Method</span></header><section><div><p>accumulator, creater, initializer = SparseAssembler()</p><p>Returns 3 functions that can be used for assembling sparse matrices concurrently.</p><ul><li><code>initializer</code> must be called before the working session</li><li><code>accumulator</code> accumulates column indices and values </li><li><code>creator</code> accepts no input and outputs row indices, column indices and values for the sparse matrix</li></ul><p><strong>Example</strong></p><pre><code class="language-none">accumulator, creater, initializer = SparseAssembler()
initializer(5)
op1 = accumulator(1, [1;2;3], ones(3))
op2 = accumulator(1, [3], [1.])
op3 = accumulator(2, [1;3], ones(2))
run(sess, [op1,op2,op3])
ii,jj,vv = creater()
i,j,v = run(sess, [ii,jj,vv])
A = sparse(i,j,v,5,5)
@assert Array(A)≈[1.0  1.0  2.0  0.0  0.0
                1.0  0.0  1.0  0.0  0.0
                0.0  0.0  0.0  0.0  0.0
                0.0  0.0  0.0  0.0  0.0
                0.0  0.0  0.0  0.0  0.0]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/sparse.jl#L252-L279">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.find-Tuple{SparseTensor}" href="#ADCME.find-Tuple{SparseTensor}"><code>ADCME.find</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">find(s::SparseTensor)</code></pre><p>Returns the row, column and values for sparse tensor <code>s</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/sparse.jl#L49-L53">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.spdiag-Tuple{Int64}" href="#ADCME.spdiag-Tuple{Int64}"><code>ADCME.spdiag</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">spdiag(n::Int64)</code></pre><p>Constructs a sparse identity matrix of size <span>$n\times n$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/sparse.jl#L304-L308">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.spdiag-Tuple{PyObject}" href="#ADCME.spdiag-Tuple{PyObject}"><code>ADCME.spdiag</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">spdiag(o::PyObject)</code></pre><p>Constructs a sparse diagonal matrix where the diagonal entries are <code>o</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/sparse.jl#L313-L317">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.spzero" href="#ADCME.spzero"><code>ADCME.spzero</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">spzero(m::Int64, n::Union{Missing, Int64}=missing)</code></pre><p>Constructs a empty sparse matrix of size <span>$m\times n$</span>. <code>n=m</code> if <code>n</code> is <code>missing</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/sparse.jl#L326-L330">source</a></section></article><h2 id="Operations-1"><a class="docs-heading-anchor" href="#Operations-1">Operations</a><a class="docs-heading-anchor-permalink" href="#Operations-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.pmap-Tuple{Function,Union{PyObject, Array{PyObject,N} where N}}" href="#ADCME.pmap-Tuple{Function,Union{PyObject, Array{PyObject,N} where N}}"><code>ADCME.pmap</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">pmap(fn::Function, o::Union{Array{PyObject}, PyObject})</code></pre><p>Parallel for loop. There should be no data dependency between different iterations.</p><p><strong>Example</strong></p><pre><code class="language-julia">x = constant(ones(10))
y1 = pmap(x-&gt;2.0*x, x)
y2 = pmap(x-&gt;x[1]+x[2], [x,x])
y3 = pmap(1:10, x) do z
    i = z[1]
    xi = z[2]
    xi + cast(Float64, i)
end
run(sess, y1)
run(sess, y2)
run(sess, y3)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/ops.jl#L624-L643">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.vector-Union{Tuple{T}, Tuple{Union{PyObject, StepRange, UnitRange, Array{T,N} where N},Union{PyObject, Array{Float64,N} where N},Union{Int64, PyObject}}} where T&lt;:Integer" href="#ADCME.vector-Union{Tuple{T}, Tuple{Union{PyObject, StepRange, UnitRange, Array{T,N} where N},Union{PyObject, Array{Float64,N} where N},Union{Int64, PyObject}}} where T&lt;:Integer"><code>ADCME.vector</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">vector(i::Union{Array{T}, PyObject, UnitRange, StepRange}, v::Union{Array{Float64},PyObject},s::Union{Int64,PyObject})</code></pre><p>Returns a vector <code>V</code> with length <code>s</code> such that</p><pre><code class="language-none">V[i] = v</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/ops.jl#L696-L703">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.svd-Tuple{PyObject,Vararg{Any,N} where N}" href="#LinearAlgebra.svd-Tuple{PyObject,Vararg{Any,N} where N}"><code>LinearAlgebra.svd</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">svd(o::PyObject, args...; kwargs...)</code></pre><p>Returns a <code>TFSVD</code> structure which holds the following data structures</p><pre><code class="language-julia">S::PyObject
U::PyObject
V::PyObject
Vt::PyObject</code></pre><p>We have the equality <span>$o = USV&#39;$</span></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/ops.jl#L580-L592">source</a></section></article><h2 id="IO-1"><a class="docs-heading-anchor" href="#IO-1">IO</a><a class="docs-heading-anchor-permalink" href="#IO-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.Diary" href="#ADCME.Diary"><code>ADCME.Diary</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Diary(suffix::Union{String, Nothing}=nothing)</code></pre><p>Creates a diary at a temporary directory path. It returns a writer and the corresponding directory path</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/io.jl#L136-L140">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.activate" href="#ADCME.activate"><code>ADCME.activate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">activate(sw::Diary, port::Int64=6006)</code></pre><p>Running <a href="#ADCME.Diary"><code>Diary</code></a> at http://localhost:port.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/io.jl#L166-L170">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load" href="#ADCME.load"><code>ADCME.load</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">load(sess::PyObject, file::String, vars::Union{PyObject, Nothing, Array{PyObject}}=nothing, args...; kwargs...)</code></pre><p>Loads the values of variables to the session <code>sess</code> from the file <code>file</code>. If <code>vars</code> is nothing, it loads values to all the trainable variables. See also <a href="#ADCME.save"><code>save</code></a>, <a href="#ADCME.load"><code>load</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/io.jl#L82-L87">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load-Tuple{Diary,String}" href="#ADCME.load-Tuple{Diary,String}"><code>ADCME.load</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">load(sw::Diary, dirp::String)</code></pre><p>Loads <a href="#ADCME.Diary"><code>Diary</code></a> from <code>dirp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/io.jl#L156-L160">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.pload-Tuple{String}" href="#ADCME.pload-Tuple{String}"><code>ADCME.pload</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">pload(file::String)</code></pre><p>Loads a Python objection from <code>file</code>. See also <a href="#ADCME.psave"><code>psave</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/io.jl#L30-L35">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.psave-Tuple{PyObject,String}" href="#ADCME.psave-Tuple{PyObject,String}"><code>ADCME.psave</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">psave(o::PyObject, file::String)</code></pre><p>Saves a Python objection <code>o</code> to <code>file</code>. See also <a href="#ADCME.pload"><code>pload</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/io.jl#L18-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.save" href="#ADCME.save"><code>ADCME.save</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">save(sess::PyObject, file::String, vars::Union{PyObject, Nothing, Array{PyObject}}=nothing, args...; kwargs...)</code></pre><p>Saves the values of <code>vars</code> in the session <code>sess</code>. The result is written into <code>file</code> as a dictionary. If <code>vars</code> is nothing, it saves all the trainable variables. See also <a href="#ADCME.save"><code>save</code></a>, <a href="#ADCME.load"><code>load</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/io.jl#L44-L49">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.save-Tuple{Diary,String}" href="#ADCME.save-Tuple{Diary,String}"><code>ADCME.save</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">save(sw::Diary, dirp::String)</code></pre><p>Saves <a href="#ADCME.Diary"><code>Diary</code></a> to <code>dirp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/io.jl#L147-L151">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.scalar" href="#ADCME.scalar"><code>ADCME.scalar</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">scalar(o::PyObject, name::String)</code></pre><p>Returns a scalar summary object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/io.jl#L176-L180">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.write-Tuple{Diary,Int64,Union{String, Array{String,N} where N}}" href="#Base.write-Tuple{Diary,Int64,Union{String, Array{String,N} where N}}"><code>Base.write</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">write(sw::Diary, step::Int64, cnt::Union{String, Array{String}})</code></pre><p>Writes to <a href="#ADCME.Diary"><code>Diary</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/io.jl#L188-L192">source</a></section></article><h2 id="Optimization-1"><a class="docs-heading-anchor" href="#Optimization-1">Optimization</a><a class="docs-heading-anchor-permalink" href="#Optimization-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.BFGS!" href="#ADCME.BFGS!"><code>ADCME.BFGS!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">BFGS!(sess::PyObject, loss::PyObject, max_iter::Int64=15000; 
vars::Array{PyObject}=PyObject[], callback::Union{Function, Nothing}=nothing, kwargs...)</code></pre><p><code>BFGS!</code> is a simplified interface for BFGS optimizer. See also <a href="#ADCME.ScipyOptimizerInterface-Tuple{Any}"><code>ScipyOptimizerInterface</code></a>. <code>callback</code> is a callback function with signature </p><pre><code class="language-julia">callback(vs::Array{Float64}, iter::Int64, loss::Float64)</code></pre><p><code>vars</code> is an array consisting of tensors and its values will be the input to <code>vs</code>.</p><p><strong>example</strong></p><pre><code class="language-julia">a = Variable(1.0)
loss = (a - 10.0)^2
BFGS!(sess, loss)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/optim.jl#L153-L170">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.BFGS!" href="#ADCME.BFGS!"><code>ADCME.BFGS!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">BFGS!(value_and_gradients_function::Function, initial_position::Union{PyObject, Array{Float64}}, max_iter::Int64=50, args...;kwargs...)</code></pre><p>Applies the BFGS optimizer to <code>value_and_gradients_function</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/optim.jl#L202-L206">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.BFGS!-Union{Tuple{T}, Tuple{PyObject,PyObject,Union{Nothing, PyObject, Array{T,N} where N},Union{PyObject, Array{PyObject,N} where N}}} where T&lt;:Union{Nothing, PyObject}" href="#ADCME.BFGS!-Union{Tuple{T}, Tuple{PyObject,PyObject,Union{Nothing, PyObject, Array{T,N} where N},Union{PyObject, Array{PyObject,N} where N}}} where T&lt;:Union{Nothing, PyObject}"><code>ADCME.BFGS!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">BFGS!(sess::PyObject, loss::PyObject, grads::Union{Array{T},Nothing,PyObject}, 
    vars::Union{Array{PyObject},PyObject}; kwargs...) where T&lt;:Union{Nothing, PyObject}</code></pre><p>Running BFGS algorithm <span>$\min_{\texttt{vars}} \texttt{loss}(\texttt{vars})$</span> The gradients <code>grads</code> must be provided. Typically, <code>grads[i] = gradients(loss, vars[i])</code>.  <code>grads[i]</code> can exist on different devices (GPU or CPU). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/optim.jl#L545-L553">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.CustomOptimizer-Tuple{Function}" href="#ADCME.CustomOptimizer-Tuple{Function}"><code>ADCME.CustomOptimizer</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">CustomOptimizer(opt::Function, name::String)</code></pre><p>creates a custom optimizer with struct name <code>name</code>. For example, we can integrate <code>Optim.jl</code> with <code>ADCME</code> by  constructing a new optimizer</p><pre><code class="language-julia">CustomOptimizer(&quot;Con&quot;) do f, df, c, dc, x0, nineq, neq, x_L, x_U
    opt = Opt(:LD_MMA, length(x0))
    bd = zeros(length(x0)); bd[end-1:end] = [-Inf, 0.0]
    opt.lower_bounds = bd
    opt.xtol_rel = 1e-4
    opt.min_objective = (x,g)-&gt;(g[:]= df(x); return f(x)[1])
    inequality_constraint!(opt, (x,g)-&gt;( g[:]= dc(x);c(x)[1]), 1e-8)
    (minf,minx,ret) = NLopt.optimize(opt, x0)
    minx
end</code></pre><p>Then we can create an optimizer with </p><pre><code class="language-none">opt = Con(loss, inequalities=[c1], equalities=[c2])</code></pre><p>To trigger the optimization, use</p><pre><code class="language-none">opt.minimize(sess)</code></pre><p>or </p><pre><code class="language-none">minimize(opt, sess)</code></pre><p>Note thanks to the global variable scope of Julia, <code>step_callback</code>, <code>optimizer_kwargs</code> can actually  be passed from Julia environment directly.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/optim.jl#L73-L105">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.NonlinearConstrainedProblem-Union{Tuple{T}, Tuple{Function,Function,Union{Array{Float64,1}, PyObject},Union{PyObject, Array{Float64,N} where N}}} where T&lt;:Real" href="#ADCME.NonlinearConstrainedProblem-Union{Tuple{T}, Tuple{Function,Function,Union{Array{Float64,1}, PyObject},Union{PyObject, Array{Float64,N} where N}}} where T&lt;:Real"><code>ADCME.NonlinearConstrainedProblem</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">NonlinearConstrainedProblem(f::Function, L::Function, θ::PyObject, u0::Union{PyObject, Array{Float64}}; options::Union{Dict{String, T}, Missing}=missing) where T&lt;:Integer</code></pre><p>Computes the gradients <span>$\frac{\partial L}{\partial \theta}$</span></p><div>\[\min \ L(u) \quad \mathrm{s.t.} \ F(\theta, u) = 0\]</div><p><code>u0</code> is the initial guess for the numerical solution <code>u</code>, see <a href="../newton_raphson/#ADCME.newton_raphson"><code>newton_raphson</code></a>.</p><p>Caveats: Assume <code>r, A = f(θ, u)</code> and <code>θ</code> are the unknown parameters, <code>gradients(r, θ)</code> must be defined (backprop works properly)</p><p>Returns: It returns a tuple (<code>L</code>: loss, <code>C</code>: constraints, and <code>Graidents</code>)</p><div>\[\left(L(u), u, \frac{\partial L}{\partial θ}\right)\]</div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/optim.jl#L482-L501">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ScipyOptimizerInterface-Tuple{Any}" href="#ADCME.ScipyOptimizerInterface-Tuple{Any}"><code>ADCME.ScipyOptimizerInterface</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ScipyOptimizerInterface(loss; method=&quot;L-BFGS-B&quot;, options=Dict(&quot;maxiter&quot;=&gt; 15000, &quot;ftol&quot;=&gt;1e-12, &quot;gtol&quot;=&gt;1e-12), kwargs...)</code></pre><p>A simple interface for Scipy Optimizer. See also <a href="#ADCME.ScipyOptimizerMinimize-Tuple{PyObject,PyObject}"><code>ScipyOptimizerMinimize</code></a> and <a href="#ADCME.BFGS!"><code>BFGS!</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/optim.jl#L46-L50">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ScipyOptimizerMinimize-Tuple{PyObject,PyObject}" href="#ADCME.ScipyOptimizerMinimize-Tuple{PyObject,PyObject}"><code>ADCME.ScipyOptimizerMinimize</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ScipyOptimizerMinimize(sess::PyObject, opt::PyObject; kwargs...)</code></pre><p>Minimizes a scalar Tensor. Variables subject to optimization are updated in-place at the end of optimization.</p><p>Note that this method does not just return a minimization Op, unlike <code>minimize</code>; instead it actually performs minimization by executing commands to control a Session https://www.tensorflow.org/api_docs/python/tf/contrib/opt/ScipyOptimizerInterface. See also <a href="#ADCME.ScipyOptimizerInterface-Tuple{Any}"><code>ScipyOptimizerInterface</code></a> and <a href="#ADCME.BFGS!"><code>BFGS!</code></a>.</p><ul><li>feed_dict: A feed dict to be passed to calls to session.run.</li><li>fetches: A list of Tensors to fetch and supply to loss_callback as positional arguments.</li><li>step_callback: A function to be called at each optimization step; arguments are the current values of all optimization variables flattened into a single vector.</li><li>loss_callback: A function to be called every time the loss and gradients are computed, with evaluated fetches supplied as positional arguments.</li><li>run_kwargs: kwargs to pass to session.run.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/optim.jl#L54-L68">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.newton_raphson-Union{Tuple{T}, Tuple{Function,Union{PyObject, Array}}, Tuple{Function,Union{PyObject, Array},Union{Missing, PyObject, Array{#s110,N} where N where #s110&lt;:Real}}} where T&lt;:Real" href="#ADCME.newton_raphson-Union{Tuple{T}, Tuple{Function,Union{PyObject, Array}}, Tuple{Function,Union{PyObject, Array},Union{Missing, PyObject, Array{#s110,N} where N where #s110&lt;:Real}}} where T&lt;:Real"><code>ADCME.newton_raphson</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">newton_raphson(f::Function, u::Union{Array,PyObject}, θ::Union{Missing,PyObject}; options::Union{Dict{String, T}, Missing}=missing)</code></pre><p>Newton Raphson solver for solving a nonlinear equation.  <code>f</code> has the signature </p><ul><li><code>f(θ::Union{Missing,PyObject}, u::PyObject)-&gt;(r::PyObject, A::Union{PyObject,SparseTensor})</code> (if <code>linesearch</code> is off)</li><li><code>f(θ::Union{Missing,PyObject}, u::PyObject)-&gt;(fval::PyObject, r::PyObject, A::Union{PyObject,SparseTensor})</code> (if <code>linesearch</code> is on)</li></ul><p>where <code>r</code> is the residual and <code>A</code> is the Jacobian matrix; in the case where <code>linesearch</code> is on, the function value <code>fval</code> must also be supplied. <code>θ</code> are external parameters. <code>u0</code> is the initial guess for <code>u</code> <code>options</code>:</p><ul><li><code>max_iter</code>: maximum number of iterations (default=100)</li><li><code>verbose</code>: whether details are printed (default=false)</li><li><code>rtol</code>: relative tolerance for termination (default=1e-12)</li><li><code>tol</code>: absolute tolerance for termination (default=1e-12)</li><li><code>LM</code>: a float number, Levenberg-Marquardt modification <span>$x^{k+1} = x^k - (J^k + \mu^k)^{-1}g^k$</span> (default=0.0)</li><li><code>linesearch</code>: whether linesearch is used (default=false)</li></ul><p>Currently, the backtracing algorithm is implemented. The parameters for <code>linesearch</code> are also supplied via <code>options</code></p><ul><li><code>ls_c1</code>: stop criterion, <span>$f(x^k) &lt; f(0) + \alpha c_1  f&#39;(0)$</span></li><li><code>ls_ρ_hi</code>: the new step size <span>$\alpha_1\leq \rho_{hi}\alpha_0$</span> </li><li><code>ls_ρ_lo</code>: the new step size <span>$\alpha_1\geq \rho_{lo}\alpha_0$</span> </li><li><code>ls_iterations</code>: maximum number of iterations for linesearch</li><li><code>ls_maxstep</code>: maximum allowable steps</li><li><code>ls_αinitial</code>: initial guess for the step size <span>$\alpha$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/optim.jl#L290-L317">source</a></section></article><h2 id="Neural-Networks-1"><a class="docs-heading-anchor" href="#Neural-Networks-1">Neural Networks</a><a class="docs-heading-anchor-permalink" href="#Neural-Networks-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae" href="#ADCME.ae"><code>ADCME.ae</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ae(x::PyObject, output_dims::Array{Int64}, scope::String = &quot;default&quot;)</code></pre><p>Creates a neural network with intermediate numbers of neurons <code>output_dims</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/layers.jl#L58-L62">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae-Tuple{Union{PyObject, Array{Float64,N} where N},Array{Int64,N} where N,Union{PyObject, Array{Float64,N} where N}}" href="#ADCME.ae-Tuple{Union{PyObject, Array{Float64,N} where N},Array{Int64,N} where N,Union{PyObject, Array{Float64,N} where N}}"><code>ADCME.ae</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ae(x::Union{Array{Float64}, PyObject}, output_dims::Array{Int64}, θ::Union{Array{Float64}, PyObject})</code></pre><p>Creates a neural network with intermediate numbers of neurons <code>output_dims</code>. The weights are given by <code>θ</code></p><p><strong>Example 1: Explicitly construct weights and biases</strong></p><pre><code class="language-julia">x = constant(rand(10,2))
n = ae_num([2,20,20,20,2])
θ = Variable(randn(n)*0.001)
y = ae(x, [20,20,20,2], θ)</code></pre><p><strong>Example 2: Implicitly construct weights and biases</strong></p><pre><code class="language-julia">θ = ae_init([10,20,20,20,2]) 
x = constant(rand(10,10))
y = ae(x, [20,20,20,2], θ)</code></pre><p>See also <a href="#ADCME.ae_num-Tuple{Array{Int64,N} where N}"><code>ae_num</code></a>, <a href="#ADCME.ae_init-Tuple{Array{Int64,N} where N}"><code>ae_init</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/layers.jl#L85-L106">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae_init-Tuple{Array{Int64,N} where N}" href="#ADCME.ae_init-Tuple{Array{Int64,N} where N}"><code>ADCME.ae_init</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ae_init(output_dims::Array{Int64}; T::Type=Float64, method::String=&quot;xavier&quot;)</code></pre><p>Return the initial weights and bias values by TensorFlow as a vector. Three types of  random initializers are provided</p><ul><li><code>xavier</code> (default). It is useful for <code>tanh</code> fully connected neural network. </li></ul><div>\[W^l_i \sim \sqrt{\frac{1}{n_{l-1}}}\]</div><ul><li><code>xavier_avg</code>. A variant of <code>xavier</code></li></ul><div>\[W^l_i \sim \sqrt{\frac{2}{n_l + n_{l-1}}}\]</div><ul><li><code>he</code>. This is the activation aware initialization of weights and helps mitigate the problem</li></ul><p>of vanishing/exploding gradients. </p><div>\[W^l_i \sim \sqrt{\frac{2}{n_{l-1}}}\]</div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/layers.jl#L142-L161">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae_num-Tuple{Array{Int64,N} where N}" href="#ADCME.ae_num-Tuple{Array{Int64,N} where N}"><code>ADCME.ae_num</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ae_num(output_dims::Array{Int64})</code></pre><p>Estimates the number of weights and biases for the neural network. Note the first dimension should be the feature dimension (this is different from <a href="#ADCME.ae"><code>ae</code></a> since in <code>ae</code> the feature dimension can be inferred), and the last dimension should be the output dimension. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/layers.jl#L183-L189">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae_to_code-Tuple{String,String}" href="#ADCME.ae_to_code-Tuple{String,String}"><code>ADCME.ae_to_code</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ae_to_code(file::String, scope::String)</code></pre><p>Return the code string from the feed-forward neural network data in <code>file</code>. Usually we can immediately evaluate  the code string into Julia session by </p><pre><code class="language-julia">eval(Meta.parse(s))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/layers.jl#L226-L234">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.bn-Tuple" href="#ADCME.bn-Tuple"><code>ADCME.bn</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">bn(args...;center = true, scale=true, kwargs...)</code></pre><p><code>bn</code> accepts a keyword parameter <code>is_training</code>. </p><p><strong>Example</strong></p><pre><code class="language-julia">bn(inputs, name=&quot;batch_norm&quot;, is_training=true)</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p><code>bn</code> should be used with <code>control_dependency</code></p><pre><code class="language-julia">update_ops = get_collection(UPDATE_OPS)
control_dependencies(update_ops) do 
    global train_step = AdamOptimizer().minimize(loss)
end </code></pre></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/layers.jl#L295-L312">source</a></section></article><h2 id="Generative-Neural-Nets-1"><a class="docs-heading-anchor" href="#Generative-Neural-Nets-1">Generative Neural Nets</a><a class="docs-heading-anchor-permalink" href="#Generative-Neural-Nets-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.GAN" href="#ADCME.GAN"><code>ADCME.GAN</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GAN(dat::PyObject, 
    generator::Function, 
    gan::GAN,
    loss::Union{String, Function, Missing}=missing; 
    latent_dim::Union{Missing, Int64}=missing, 
    batch_size::Union{Missing, Int64}=missing)</code></pre><p>Creates a GAN instance. </p><ul><li><code>dat</code> <span>$\in \mathbb{R}^{n\times d}$</span> is the training data for the GAN, where <span>$n$</span> is the number of training data, and <span>$d$</span> is the dimension per training data.</li><li><code>generator</code><span>$:\mathbb{R}^{d&#39;} \rightarrow \mathbb{R}^d$</span> is the generator function, <span>$d&#39;$</span> is the hidden dimension.</li><li><code>discriminator</code><span>$:\mathbb{R}^{d} \rightarrow \mathbb{R}$</span> is the discriminator function. </li><li><code>loss</code> is the loss function. See <a href="#ADCME.klgan-Tuple{GAN}"><code>klgan</code></a>, <a href="#ADCME.rklgan-Tuple{GAN}"><code>rklgan</code></a>, <a href="#ADCME.wgan-Tuple{GAN}"><code>wgan</code></a>, <a href="#ADCME.lsgan-Tuple{GAN}"><code>lsgan</code></a> for examples.</li><li><code>latent_dim</code> (default=<span>$d$</span>) is the latent dimension.</li><li><code>batch_size</code> (default=32) is the batch size in training.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/gan.jl#L34-L50">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.jsgan-Tuple{GAN}" href="#ADCME.jsgan-Tuple{GAN}"><code>ADCME.jsgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">jsgan(gan::GAN)</code></pre><p>Computes the vanilla GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/gan.jl#L84-L88">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.klgan-Tuple{GAN}" href="#ADCME.klgan-Tuple{GAN}"><code>ADCME.klgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">klgan(gan::GAN)</code></pre><p>Computes the KL-divergence GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/gan.jl#L70-L74">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.lsgan-Tuple{GAN}" href="#ADCME.lsgan-Tuple{GAN}"><code>ADCME.lsgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">lsgan(gan::GAN)</code></pre><p>Computes the least square GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/gan.jl#L126-L130">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.predict-Tuple{GAN,Union{PyObject, Array}}" href="#ADCME.predict-Tuple{GAN,Union{PyObject, Array}}"><code>ADCME.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">predict(gan::GAN, input::Union{PyObject, Array})</code></pre><p>Predicts the GAN <code>gan</code> output given input <code>input</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/gan.jl#L182-L186">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.rklgan-Tuple{GAN}" href="#ADCME.rklgan-Tuple{GAN}"><code>ADCME.rklgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">rklgan(gan::GAN)</code></pre><p>Computes the reverse KL-divergence GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/gan.jl#L112-L116">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.sample-Tuple{GAN,Int64}" href="#ADCME.sample-Tuple{GAN,Int64}"><code>ADCME.sample</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sample(gan::GAN, n::Int64)</code></pre><p>Samples <code>n</code> instances from <code>gan</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/gan.jl#L166-L170">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.wgan-Tuple{GAN}" href="#ADCME.wgan-Tuple{GAN}"><code>ADCME.wgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">wgan(gan::GAN)</code></pre><p>Computes the Wasserstein GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/gan.jl#L98-L102">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.build!-Tuple{GAN}" href="#ADCME.build!-Tuple{GAN}"><code>ADCME.build!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">build!(gan::GAN)</code></pre><p>Builds the GAN instances. This function returns <code>gan</code> for convenience.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/gan.jl#L141-L145">source</a></section></article><h2 id="Tools-1"><a class="docs-heading-anchor" href="#Tools-1">Tools</a><a class="docs-heading-anchor-permalink" href="#Tools-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.compile_op-Tuple{String}" href="#ADCME.compile_op-Tuple{String}"><code>ADCME.compile_op</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">compile_op(oplibpath::String; check::Bool=false)</code></pre><p>Compile the library operator by force.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/extra.jl#L51-L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.customop-Tuple{}" href="#ADCME.customop-Tuple{}"><code>ADCME.customop</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">customop()</code></pre><p>Create a new custom operator.</p><p><strong>example</strong></p><pre><code class="language-julia-repl">julia&gt; customop() # create an editable `customop.txt` file
[ Info: Edit custom_op.txt for custom operators
julia&gt; customop() # after editing `customop.txt`, call it again to generate interface files.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/extra.jl#L223-L234">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.install-Tuple{String}" href="#ADCME.install-Tuple{String}"><code>ADCME.install</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">install(s::String; force::Bool = false)</code></pre><p>Install a custom operator via URL. <code>s</code> can be</p><ul><li>A URL. ADCME will download the directory through <code>git</code></li><li>A string. ADCME will search for the associated package on https://github.com/ADCMEMarket</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/extra.jl#L350-L356">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load_op-Tuple{String,String}" href="#ADCME.load_op-Tuple{String,String}"><code>ADCME.load_op</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">load_op(oplibpath::String, opname::String)</code></pre><p>Loads the operator <code>opname</code> from library <code>oplibpath</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/extra.jl#L78-L82">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load_op_and_grad-Tuple{String,String}" href="#ADCME.load_op_and_grad-Tuple{String,String}"><code>ADCME.load_op_and_grad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">load_op_and_grad(oplibpath::String, opname::String; multiple::Bool=false)</code></pre><p>Loads the operator <code>opname</code> from library <code>oplibpath</code>; gradients are also imported.  If <code>multiple</code> is true, the operator is assumed to have multiple outputs. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/extra.jl#L108-L113">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load_system_op" href="#ADCME.load_system_op"><code>ADCME.load_system_op</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">load_system_op(s::String, oplib::String, grad::Bool=true)</code></pre><p>Loads custom operator from CustomOps directory (shipped with ADCME instead of TensorFlow) For example </p><pre><code class="language-none">s = &quot;SparseOperator&quot;
oplib = &quot;libSO&quot;
grad = true</code></pre><p>this will direct Julia to find library <code>CustomOps/SparseOperator/libSO.dylib</code> on MACOSX</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/extra.jl#L159-L170">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.test_jacobian-Tuple{Function,Array{Float64,N} where N}" href="#ADCME.test_jacobian-Tuple{Function,Array{Float64,N} where N}"><code>ADCME.test_jacobian</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">test_jacobian(f::Function, x0::Array{Float64}; scale::Float64 = 1.0)</code></pre><p>Testing the gradients of a vector function <code>f</code>: <code>y, J = f(x)</code> where <code>y</code> is a vector output and <code>J</code> is the Jacobian.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/extra.jl#L318-L323">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.xavier_init" href="#ADCME.xavier_init"><code>ADCME.xavier_init</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">xavier_init(size, dtype=Float64)</code></pre><p>Returns a matrix of size <code>size</code> and its values are from Xavier initialization. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/extra.jl#L14-L18">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.compile-Tuple{String}" href="#ADCME.compile-Tuple{String}"><code>ADCME.compile</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">compile(s::String)</code></pre><p>Compiles the library <code>s</code> by force.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/50c2008d3dab8234961dd77ebb68167c5f50b3a6/src/extra.jl#L198-L202">source</a></section></article><h2 id="Datasets-1"><a class="docs-heading-anchor" href="#Datasets-1">Datasets</a><a class="docs-heading-anchor-permalink" href="#Datasets-1" title="Permalink"></a></h2></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../apps_constitutive_law/">« Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 1 December 2019 06:54">Sunday 1 December 2019</span>. Using Julia version 1.2.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
