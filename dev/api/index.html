<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API Reference · ADCME</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="ADCME logo"/></a><div class="docs-package-name"><span class="docs-autofit">ADCME</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../tutorial/">Overview</a></li><li><a class="tocitem" href="../tu_whatis/">What is ADCME? Computational Graph, Automatic Differentiation &amp; TensorFlow</a></li><li><a class="tocitem" href="../tu_basic/">ADCME Basics: Tensor, Type, Operator, Session &amp; Kernel</a></li><li><a class="tocitem" href="../tu_sparse/">Sparse Linear Algebra</a></li><li><a class="tocitem" href="../tu_fd/">Numerical Scheme in ADCME: Finite Difference Example</a></li><li><a class="tocitem" href="../tu_fem/">Numerical Scheme in ADCME: Finite Element Example</a></li><li><a class="tocitem" href="../tu_inv/">Inverse Modeling with ADCME</a></li><li><a class="tocitem" href="../tu_implicit/">Advanced: Automatic Differentiation for Implicit Operators</a></li></ul></li><li><span class="tocitem">Resources</span><ul><li><a class="tocitem" href="../newton_raphson/">Newton Raphson</a></li><li><a class="tocitem" href="../parallel/">Parallel Computing</a></li><li><a class="tocitem" href="../ode/">PDE/ODE Solvers</a></li><li><a class="tocitem" href="../customop/">Custom Operators</a></li><li><a class="tocitem" href="../global/">Shared Memory Across Kernels</a></li><li><a class="tocitem" href="../julia_customop/">Julia Custom Operators</a></li><li><a class="tocitem" href="../pytorchnn/">Neural Network in C++</a></li><li><a class="tocitem" href="../extra/">Miscellaneous Tools</a></li><li><a class="tocitem" href="../ot/">Optimal Transport</a></li><li><a class="tocitem" href="../resource_manager/">Resource Manager</a></li></ul></li><li><span class="tocitem">Applications</span><ul><li><a class="tocitem" href="../apps_ana/">Adversarial Numerical Analysis</a></li><li><a class="tocitem" href="../apps_levy/">Calibrating Multivariate Lévy Processes with Neural Networks</a></li><li><a class="tocitem" href="../apps_constitutive_law/">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></li><li><a class="tocitem" href="../apps_ad/">Intelligent Automatic Differentiation</a></li></ul></li><li class="is-active"><a class="tocitem" href>API Reference</a><ul class="internal"><li><a class="tocitem" href="#Core-Functions-1"><span>Core Functions</span></a></li><li><a class="tocitem" href="#Variables-1"><span>Variables</span></a></li><li><a class="tocitem" href="#Random-Variables-1"><span>Random Variables</span></a></li><li><a class="tocitem" href="#Sparse-Matrix-1"><span>Sparse Matrix</span></a></li><li><a class="tocitem" href="#Operations-1"><span>Operations</span></a></li><li><a class="tocitem" href="#IO-1"><span>IO</span></a></li><li><a class="tocitem" href="#Optimization-1"><span>Optimization</span></a></li><li><a class="tocitem" href="#Neural-Networks-1"><span>Neural Networks</span></a></li><li><a class="tocitem" href="#Generative-Neural-Nets-1"><span>Generative Neural Nets</span></a></li><li><a class="tocitem" href="#Tools-1"><span>Tools</span></a></li><li><a class="tocitem" href="#Misc-1"><span>Misc</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="API-Reference-1"><a class="docs-heading-anchor" href="#API-Reference-1">API Reference</a><a class="docs-heading-anchor-permalink" href="#API-Reference-1" title="Permalink"></a></h1><h2 id="Core-Functions-1"><a class="docs-heading-anchor" href="#Core-Functions-1">Core Functions</a><a class="docs-heading-anchor-permalink" href="#Core-Functions-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.add_collection-Tuple{String,PyObject}" href="#ADCME.add_collection-Tuple{String,PyObject}"><code>ADCME.add_collection</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">add_collection(name::String, v::PyObject)</code></pre><p>Adds <code>v</code> to the collection with name <code>name</code>. If <code>name</code> does not exist, a new one is created.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/core.jl#L43-L47">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.add_collection-Tuple{String,Vararg{PyObject,N} where N}" href="#ADCME.add_collection-Tuple{String,Vararg{PyObject,N} where N}"><code>ADCME.add_collection</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">add_collection(name::String, vs::PyObject...)</code></pre><p>Adds operators <code>vs</code> to the collection with name <code>name</code>. If <code>name</code> does not exist, a new one is created.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/core.jl#L53-L57">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.control_dependencies-Tuple{Any,Union{Tuple, PyObject, Array{PyObject,N} where N}}" href="#ADCME.control_dependencies-Tuple{Any,Union{Tuple, PyObject, Array{PyObject,N} where N}}"><code>ADCME.control_dependencies</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">control_dependencies(f, ops::Union{Array{PyObject}, PyObject})</code></pre><p>Executes all operations in <code>ops</code> before any operations <em>created</em> inside the block. </p><pre><code class="language-julia">op1 = tf.print(&quot;print op1&quot;)
op3 = tf.print(&quot;print op3&quot;)
control_dependencies(op1) do
    global op2 = tf.print(&quot;print op2&quot;)
end
run(sess, [op2,op3])</code></pre><p>In this example, <code>op1</code> must be executed before <code>op2</code>. But there is no guarantee when <code>op3</code> will be executed.  There are several possible outputs of the program such as</p><pre><code class="language-julia-repl">print op3
print op1
print op2</code></pre><p>or </p><pre><code class="language-none">print op1
print op3
print op2</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/core.jl#L108-L134">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_collection" href="#ADCME.get_collection"><code>ADCME.get_collection</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_collection(name::Union{String, Missing})</code></pre><p>Returns the collection with name <code>name</code>. If <code>name</code> is <code>missing</code>, returns all the trainable variables.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/core.jl#L25-L29">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.has_gpu-Tuple{}" href="#ADCME.has_gpu-Tuple{}"><code>ADCME.has_gpu</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">has_gpu()</code></pre><p>Checks if GPU is available.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>ADCME will use GPU automatically if GPU is available. To disable GPU, set the environment variable <code>ENV[&quot;CUDA_VISIBLE_DEVICES&quot;]=&quot;&quot;</code> before importing ADCME </p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/core.jl#L244-L251">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.if_else-Tuple{Union{Bool, PyObject, Array},Any,Any,Vararg{Any,N} where N}" href="#ADCME.if_else-Tuple{Union{Bool, PyObject, Array},Any,Any,Vararg{Any,N} where N}"><code>ADCME.if_else</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">if_else(condition::Union{PyObject,Array,Bool}, fn1, fn2, args...;kwargs...)</code></pre><ul><li>If <code>condition</code> is a scalar boolean, it outputs <code>fn1</code> or <code>fn2</code> (a function with no input argument or a tensor) based on whether <code>condition</code> is true or false.</li><li>If <code>condition</code> is a boolean array, if returns <code>condition .* fn1 + (1 - condition) .* fn2</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/core.jl#L227-L232">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.independent-Tuple{PyObject,Vararg{Any,N} where N}" href="#ADCME.independent-Tuple{PyObject,Vararg{Any,N} where N}"><code>ADCME.independent</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">independent(o::PyObject, args...; kwargs...)</code></pre><p>Returns <code>o</code> but when computing the gradients, the top gradients will not be back-propagated into dependent variables of <code>o</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/core.jl#L261-L265">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.reset_default_graph-Tuple{}" href="#ADCME.reset_default_graph-Tuple{}"><code>ADCME.reset_default_graph</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">reset_default_graph()</code></pre><p>Resets the graph by removing all the operators. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/core.jl#L19-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.tensor-Tuple{String}" href="#ADCME.tensor-Tuple{String}"><code>ADCME.tensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tensor(s::String)</code></pre><p>Returns the tensor with name <code>s</code>. See <a href="#ADCME.tensorname-Tuple{PyObject}"><code>tensorname</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/core.jl#L65-L69">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.tensorname-Tuple{PyObject}" href="#ADCME.tensorname-Tuple{PyObject}"><code>ADCME.tensorname</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tensorname(o::PyObject)</code></pre><p>Returns the name of the tensor. See <a href="#ADCME.tensor-Tuple{String}"><code>tensor</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/core.jl#L74-L78">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.while_loop-Tuple{Union{Function, PyObject},Function,Union{PyObject, Array{Any,N} where N, Array{PyObject,N} where N}}" href="#ADCME.while_loop-Tuple{Union{Function, PyObject},Function,Union{PyObject, Array{Any,N} where N, Array{PyObject,N} where N}}"><code>ADCME.while_loop</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">while_loop(condition::Union{PyObject,Function}, body::Function, loop_vars::Union{PyObject, Array{Any}, Array{PyObject}};
    parallel_iterations::Int64=10, kwargs...)</code></pre><p>Loops over <code>loop_vars</code> while <code>condition</code> is true. This operator only creates one extra node to mark the loops in the computational graph.</p><p><strong>Example</strong></p><p>The following script computes </p><div>\[\sum_{i=1}^10 i\]</div><pre><code class="language-julia">function condition(i, ta)
    i &lt;= 10
end
function body(i, ta)
    u = read(ta, i-1)
    ta = write(ta, i, u+1)
    i+1, ta
end
ta = TensorArray(10)
ta = write(ta, 1, constant(1.0))
i = constant(2, dtype=Int32)
_, out = while_loop(condition, body, [i, ta])
summation = stack(out)[10]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/core.jl#L163-L191">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.run_profile-Tuple" href="#ADCME.run_profile-Tuple"><code>ADCME.run_profile</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">run_profile(args...;kwargs...)</code></pre><p>Runs the session with tracing information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/run.jl#L32-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.save_profile" href="#ADCME.save_profile"><code>ADCME.save_profile</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">save_profile(filename::String=&quot;default_timeline.json&quot;)</code></pre><p>Save the timeline information to file <code>filename</code>. </p><ul><li>Open Chrome and navigate to chrome://tracing</li><li>Load the timeline file</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/run.jl#L44-L50">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.bind-Tuple{PyObject,Vararg{Any,N} where N}" href="#Base.bind-Tuple{PyObject,Vararg{Any,N} where N}"><code>Base.bind</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">bind(op::PyObject, ops...)</code></pre><p>Adding operations <code>ops</code> to the dependencies of <code>op</code>. The function is useful when we want to execute <code>ops</code> but <code>ops</code> is not  in the dependency of the final output. For example, if we want to print <code>i</code> each time <code>i</code> is evaluated</p><pre><code class="language-julia">i = constant(1.0)
op = tf.print(i)
i = bind(i, op)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/core.jl#L144-L154">source</a></section></article><h2 id="Variables-1"><a class="docs-heading-anchor" href="#Variables-1">Variables</a><a class="docs-heading-anchor-permalink" href="#Variables-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.TensorArray" href="#ADCME.TensorArray"><code>ADCME.TensorArray</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">TensorArray(size_::Int64=0, args...;kwargs...)</code></pre><p>Constructs a tensor array for <a href="#ADCME.while_loop-Tuple{Union{Function, PyObject},Function,Union{PyObject, Array{Any,N} where N, Array{PyObject,N} where N}}"><code>while_loop</code></a>.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/variable.jl#L452-L456">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.Variable-Tuple{Any}" href="#ADCME.Variable-Tuple{Any}"><code>ADCME.Variable</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Variable(initial_value;kwargs...)</code></pre><p>Constructs a ref tensor from <code>value</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/variable.jl#L44-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.cell-Tuple{Array,Vararg{Any,N} where N}" href="#ADCME.cell-Tuple{Array,Vararg{Any,N} where N}"><code>ADCME.cell</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cell(arr::Array, args...;kwargs...)</code></pre><p>Construct a cell tensor. </p><p><strong>Example</strong></p><pre><code class="language-julia-REPL">julia&gt; r = cell([[1.],[2.,3.]])
julia&gt; run(sess, r[1])
1-element Array{Float32,1}:
 1.0
julia&gt; run(sess, r[2])
2-element Array{Float32,1}:
 2.0
 3.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/variable.jl#L57-L72">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.constant-Tuple{Any}" href="#ADCME.constant-Tuple{Any}"><code>ADCME.constant</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">constant(value; kwargs...)</code></pre><p>Constructs a non-trainable tensor from <code>value</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/variable.jl#L28-L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.convert_to_tensor-Union{Tuple{Union{Missing, Nothing, Number, PyObject, Array{T,N} where N}}, Tuple{T}} where T&lt;:Number" href="#ADCME.convert_to_tensor-Union{Tuple{Union{Missing, Nothing, Number, PyObject, Array{T,N} where N}}, Tuple{T}} where T&lt;:Number"><code>ADCME.convert_to_tensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">convert_to_tensor(o::Union{PyObject, Number, Array{T}, Missing, Nothing}; dtype::Union{Type, Missing}=missing) where T&lt;:Number
convert_to_tensor(os::Array, dtypes::Array)</code></pre><p>Converts the input <code>o</code> to tensor. If <code>o</code> is already a tensor and <code>dtype</code> (if provided) is the same as that of <code>o</code>, the operator does nothing. Otherwise, <code>convert_to_tensor</code> converts the numerical array to a constant tensor or casts the data type. <code>convert_to_tensor</code> also accepts multiple tensors. </p><p><strong>Example</strong></p><pre><code class="language-julia">convert_to_tensor([1.0, constant(rand(2)), rand(10)], [Float32, Float64, Float32])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/variable.jl#L490-L502">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.gradient_checkpointing" href="#ADCME.gradient_checkpointing"><code>ADCME.gradient_checkpointing</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gradient_checkpointing(type::String=&quot;speed&quot;)</code></pre><p>Uses checkpointing scheme for gradients. </p><ul><li>&#39;speed&#39;:  checkpoint all outputs of convolutions and matmuls. these ops are usually the most expensive,   so checkpointing them maximizes the running speed   (this is a good option if nonlinearities, concats, batchnorms, etc are taking up a lot of memory)</li><li>&#39;memory&#39;: try to minimize the memory usage   (currently using a very simple strategy that identifies a number of bottleneck tensors in the graph to checkpoint)</li><li>&#39;collection&#39;: look for a tensorflow collection named &#39;checkpoints&#39;, which holds the tensors to checkpoint</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/variable.jl#L528-L538">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.gradients-Tuple{PyObject,PyObject}" href="#ADCME.gradients-Tuple{PyObject,PyObject}"><code>ADCME.gradients</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">gradients(ys::PyObject, xs::PyObject; kwargs...)</code></pre><p>Computes the gradients of <code>ys</code> w.r.t <code>xs</code>. </p><ul><li>If <code>ys</code> is a scalar, <code>gradients</code> returns the gradients with the same shape as <code>xs</code>.</li><li>If <code>ys</code> is a vector, <code>gradients</code> returns the Jacobian <span>$\frac{\partial y}{\partial x}$</span></li></ul><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The second usage is not suggested since <code>ADCME</code> adopts reverse mode automatic differentiation.  Although in the case <code>ys</code> is a vector and <code>xs</code> is a scalar, <code>gradients</code> cleverly uses forward mode automatic differentiation, it requires that the second order gradients are implemented for relevant operators. </p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/variable.jl#L161-L173">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.hessian-Tuple{PyObject,PyObject}" href="#ADCME.hessian-Tuple{PyObject,PyObject}"><code>ADCME.hessian</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>hessian</code> computes the hessian of a scalar function f with respect to vector inputs xs</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/variable.jl#L272-L274">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.tensor-Union{Tuple{Array{T,1}}, Tuple{T}} where T" href="#ADCME.tensor-Union{Tuple{Array{T,1}}, Tuple{T}} where T"><code>ADCME.tensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tensor(v::Array{T,2}; dtype=Float64, sparse=false) where T</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/variable.jl#L402-L404">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.tensor-Union{Tuple{Array{T,2}}, Tuple{T}} where T" href="#ADCME.tensor-Union{Tuple{Array{T,2}}, Tuple{T}} where T"><code>ADCME.tensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tensor(v::Array{T,2}; dtype=Float64, sparse=false) where T</code></pre><p>Convert a generic array <code>v</code> to a tensor. For example, </p><pre><code class="language-julia">v = [0.0 constant(1.0) 2.0
    constant(2.0) 0.0 1.0]
u = tensor(v)</code></pre><p><code>u</code> will be a <span>$2\times 3$</span> tensor. </p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>This function is expensive. Use with caution.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/variable.jl#L421-L433">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.read-Tuple{PyObject,Union{Integer, PyObject}}" href="#Base.read-Tuple{PyObject,Union{Integer, PyObject}}"><code>Base.read</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">read(ta::PyObject, i::Union{PyObject,Integer})</code></pre><p>Reads data from <a href="#ADCME.TensorArray"><code>TensorArray</code></a> at index <code>i</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/variable.jl#L472-L477">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.write-Tuple{PyObject,Union{Integer, PyObject},PyObject}" href="#Base.write-Tuple{PyObject,Union{Integer, PyObject},PyObject}"><code>Base.write</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">write(ta::PyObject, i::Union{PyObject,Integer}, obj)</code></pre><p>Writes data <code>obj</code> to <a href="#ADCME.TensorArray"><code>TensorArray</code></a> at index <code>i</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/variable.jl#L481-L486">source</a></section></article><h2 id="Random-Variables-1"><a class="docs-heading-anchor" href="#Random-Variables-1">Random Variables</a><a class="docs-heading-anchor-permalink" href="#Random-Variables-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.categorical-Tuple{Union{Integer, PyObject}}" href="#ADCME.categorical-Tuple{Union{Integer, PyObject}}"><code>ADCME.categorical</code></a> — <span class="docstring-category">Method</span></header><section><div><p>categorical(n::Union{PyObject, Integer}; kwargs...)</p><p><code>kwargs</code> has a keyword argument <code>logits</code>, a 2-D Tensor with shape <code>[batch_size, num_classes]</code>.   Each slice <code>[i, :]</code> represents the unnormalized log-probabilities for all classes.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/random.jl#L16-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.choice-Tuple{Union{PyObject, Array},Union{Integer, PyObject}}" href="#ADCME.choice-Tuple{Union{PyObject, Array},Union{Integer, PyObject}}"><code>ADCME.choice</code></a> — <span class="docstring-category">Method</span></header><section><div><p>choice(inputs::Union{PyObject, Array}, n_samples::Union{PyObject, Integer};replace::Bool=false)</p><p>Choose <code>n_samples</code> samples from <code>inputs</code> with/without replacement. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/random.jl#L41-L45">source</a></section></article><h2 id="Sparse-Matrix-1"><a class="docs-heading-anchor" href="#Sparse-Matrix-1">Sparse Matrix</a><a class="docs-heading-anchor-permalink" href="#Sparse-Matrix-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.SparseTensor-Tuple{SparseArrays.SparseMatrixCSC}" href="#ADCME.SparseTensor-Tuple{SparseArrays.SparseMatrixCSC}"><code>ADCME.SparseTensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">SparseTensor(A::SparseMatrixCSC)
SparseTensor(A::Array{Float64, 2})</code></pre><p>Creates a <code>SparseTensor</code> from numerical arrays. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/sparse.jl#L94-L99">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.SparseTensor-Union{Tuple{S}, Tuple{T}, Tuple{Union{Array{T,1}, PyObject},Union{Array{T,1}, PyObject},Union{Array{Float64,1}, PyObject}}, Tuple{Union{Array{T,1}, PyObject},Union{Array{T,1}, PyObject},Union{Array{Float64,1}, PyObject},Union{Nothing, PyObject, S}}, Tuple{Union{Array{T,1}, PyObject},Union{Array{T,1}, PyObject},Union{Array{Float64,1}, PyObject},Union{Nothing, PyObject, S},Union{Nothing, PyObject, S}}} where S&lt;:Integer where T&lt;:Integer" href="#ADCME.SparseTensor-Union{Tuple{S}, Tuple{T}, Tuple{Union{Array{T,1}, PyObject},Union{Array{T,1}, PyObject},Union{Array{Float64,1}, PyObject}}, Tuple{Union{Array{T,1}, PyObject},Union{Array{T,1}, PyObject},Union{Array{Float64,1}, PyObject},Union{Nothing, PyObject, S}}, Tuple{Union{Array{T,1}, PyObject},Union{Array{T,1}, PyObject},Union{Array{Float64,1}, PyObject},Union{Nothing, PyObject, S},Union{Nothing, PyObject, S}}} where S&lt;:Integer where T&lt;:Integer"><code>ADCME.SparseTensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">SparseTensor(I::Union{PyObject,Array{T,1}}, J::Union{PyObject,Array{T,1}}, V::Union{Array{Float64,1}, PyObject}, m::Union{S, PyObject, Nothing}=nothing, n::Union{S, PyObject, Nothing}=nothing) where {T&lt;:Integer, S&lt;:Integer}</code></pre><p>Constructs a sparse tensor.  Examples:</p><pre><code class="language-none">ii = [1;2;3;4]
jj = [1;2;3;4]
vv = [1.0;1.0;1.0;1.0]
s = SparseTensor(ii, jj, vv, 4, 4)
s = SparseTensor(sprand(10,10,0.3))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/sparse.jl#L26-L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.SparseAssembler" href="#ADCME.SparseAssembler"><code>ADCME.SparseAssembler</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">SparseAssembler(handle::Union{PyObject, &lt;:Integer}, n::Union{PyObject, &lt;:Integer}, tol::Union{PyObject, &lt;:Real}=0.0)</code></pre><p>Creates a SparseAssembler for accumulating <code>row</code>, <code>col</code>, <code>val</code> for sparse matrices. </p><ul><li><code>handle</code>: an integer handle for creating a sparse matrix. If the handle already exists, <code>SparseAssembler</code> return the existing sparse matrix handle. If you are creating different sparse matrices, the handles should be different. </li><li><code>n</code>: Number of rows of the sparse matrix. </li><li><code>tol</code> (optional): Tolerance. <code>SparseAssembler</code> will treats any values less than <code>tol</code> as zero. </li></ul><p><strong>Example 1</strong></p><pre><code class="language-julia">handle = SparseAssembler(100, 5, 1e-8)
op1 = accumulate(handle, 1, [1;2;3], [1.0;2.0;3.0])
op2 = accumulate(handle, 2, [1;2;3], [1.0;2.0;3.0])
J = assemble(5, 5, [op1;op2])</code></pre><p><code>J</code> will be a <a href="../api/#ADCME.SparseTensor-Tuple{SparseArrays.SparseMatrixCSC}"><code>SparseTensor</code></a> object. </p><p><strong>Example 2</strong></p><pre><code class="language-julia">handle = SparseAssembler(0, 5)
op1 = accumulate(handle, 1, [1;2;3], ones(3))
op2 = accumulate(handle, 1, [3], [1.])
op3 = accumulate(handle, 2, [1;3], ones(2))
J = assemble(5, 5, [op1;op2;op3]) # op1, op2, op3 are parallel
Array(run(sess, J))≈[1.0  1.0  2.0  0.0  0.0
                1.0  0.0  1.0  0.0  0.0
                0.0  0.0  0.0  0.0  0.0
                0.0  0.0  0.0  0.0  0.0
                0.0  0.0  0.0  0.0  0.0]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/sparse.jl#L373-L403">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.assemble-Tuple{Union{PyObject, #s195} where #s195&lt;:Integer,Union{PyObject, #s139} where #s139&lt;:Integer,PyObject}" href="#ADCME.assemble-Tuple{Union{PyObject, #s195} where #s195&lt;:Integer,Union{PyObject, #s139} where #s139&lt;:Integer,PyObject}"><code>ADCME.assemble</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">assemble(m::Union{PyObject, &lt;:Integer}, n::Union{PyObject, &lt;:Integer}, ops::PyObject)</code></pre><p>Assembles the sparse matrix from the <code>ops</code> created by <a href="#Base.accumulate"><code>accumulate</code></a>. <code>ops</code> is either a single output from <code>accumulate</code>, or concated from several <code>ops</code></p><pre><code class="language-julia">op1 = accumulate(handle, 1, [1;2;3], [1.0;2.0;3.0])
op2 = accumulate(handle, 2, [1;2;3], [1.0;2.0;3.0])
op = [op1;op2] # equivalent to `vcat([op1, op2]...)`</code></pre><p><code>m</code> and <code>n</code> are rows and columns of the sparse matrix. </p><p>See <a href="#ADCME.SparseAssembler"><code>SparseAssembler</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/sparse.jl#L440-L452">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.find-Tuple{SparseTensor}" href="#ADCME.find-Tuple{SparseTensor}"><code>ADCME.find</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">find(s::SparseTensor)</code></pre><p>Returns the row, column and values for sparse tensor <code>s</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/sparse.jl#L63-L67">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.scatter_add-Union{Tuple{T}, Tuple{S}, Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}},Union{Colon, UnitRange{T}, Array{S,1}, Integer, PyObject},Union{Colon, UnitRange{T}, Array{T,1}, Integer, PyObject},Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}}}} where T&lt;:Real where S&lt;:Real" href="#ADCME.scatter_add-Union{Tuple{T}, Tuple{S}, Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}},Union{Colon, UnitRange{T}, Array{S,1}, Integer, PyObject},Union{Colon, UnitRange{T}, Array{T,1}, Integer, PyObject},Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}}}} where T&lt;:Real where S&lt;:Real"><code>ADCME.scatter_add</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">scatter_update(A::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}},
i1::Union{Integer, Colon, UnitRange{T}, PyObject,Array{S,1}},
i2::Union{Integer, Colon, UnitRange{T}, PyObject,Array{T,1}},
B::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}})  where {S&lt;:Real,T&lt;:Real}</code></pre><p>Adds <code>B</code> to a subblock of a sparse matrix <code>A</code>. Equivalently, </p><pre><code class="language-none">A[i1, i2] += B</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/sparse.jl#L301-L311">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.scatter_update-Union{Tuple{T}, Tuple{S}, Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}},Union{Colon, UnitRange{T}, Array{S,1}, Integer, PyObject},Union{Colon, UnitRange{T}, Array{T,1}, Integer, PyObject},Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}}}} where T&lt;:Real where S&lt;:Real" href="#ADCME.scatter_update-Union{Tuple{T}, Tuple{S}, Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}},Union{Colon, UnitRange{T}, Array{S,1}, Integer, PyObject},Union{Colon, UnitRange{T}, Array{T,1}, Integer, PyObject},Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}}}} where T&lt;:Real where S&lt;:Real"><code>ADCME.scatter_update</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">scatter_update(A::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}},
i1::Union{Integer, Colon, UnitRange{T}, PyObject,Array{S,1}},
i2::Union{Integer, Colon, UnitRange{T}, PyObject,Array{T,1}},
B::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}})  where {S&lt;:Real,T&lt;:Real}</code></pre><p>Updates a subblock of a sparse matrix by <code>B</code>. Equivalently, </p><pre><code class="language-none">A[i1, i2] = B</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/sparse.jl#L266-L276">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.spdiag-Tuple{Int64}" href="#ADCME.spdiag-Tuple{Int64}"><code>ADCME.spdiag</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">spdiag(n::Int64)</code></pre><p>Constructs a sparse identity matrix of size <span>$n\times n$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/sparse.jl#L466-L470">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.spdiag-Tuple{Integer,Vararg{Pair,N} where N}" href="#ADCME.spdiag-Tuple{Integer,Vararg{Pair,N} where N}"><code>ADCME.spdiag</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">spdiag(m::Integer, pair::Pair...)</code></pre><p>Constructs a square <span>$m\times m$</span> <a href="#ADCME.SparseTensor-Tuple{SparseArrays.SparseMatrixCSC}"><code>SparseTensor</code></a> from pairs of the form </p><pre><code class="language-none">offset =&gt; array </code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/sparse.jl#L542-L550">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.spdiag-Tuple{PyObject}" href="#ADCME.spdiag-Tuple{PyObject}"><code>ADCME.spdiag</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">spdiag(o::PyObject)</code></pre><p>Constructs a sparse diagonal matrix where the diagonal entries are <code>o</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/sparse.jl#L475-L479">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.spzero" href="#ADCME.spzero"><code>ADCME.spzero</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">spzero(m::Int64, n::Union{Missing, Int64}=missing)</code></pre><p>Constructs a empty sparse matrix of size <span>$m\times n$</span>. <code>n=m</code> if <code>n</code> is <code>missing</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/sparse.jl#L488-L492">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.accumulate-Tuple{PyObject,Union{PyObject, #s195} where #s195&lt;:Integer,Union{PyObject, Array{#s139,N} where N where #s139&lt;:Integer},Union{PyObject, Array{#s138,N} where N where #s138&lt;:Real}}" href="#Base.accumulate-Tuple{PyObject,Union{PyObject, #s195} where #s195&lt;:Integer,Union{PyObject, Array{#s139,N} where N where #s139&lt;:Integer},Union{PyObject, Array{#s138,N} where N where #s138&lt;:Real}}"><code>Base.accumulate</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">accumulate(handle::PyObject, row::Union{PyObject, &lt;:Integer}, cols::Union{PyObject, Array{&lt;:Integer}}, vals::Union{PyObject, Array{&lt;:Real}})</code></pre><p>Accumulates <code>row</code>-th row. It adds the value to the sparse matrix</p><pre><code class="language-julia">for k = 1:length(cols)
    A[row, cols[k]] += vals[k]
end</code></pre><p><code>handle</code> is the handle created by <a href="#ADCME.SparseAssembler"><code>SparseAssembler</code></a>. </p><p>See <a href="#ADCME.SparseAssembler"><code>SparseAssembler</code></a> for an example.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The function <code>accumulate</code> returns a <code>op::PyObject</code>. Only when <code>op</code> is executed, the nonzero values are populated into the sparse matrix. </p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/sparse.jl#L414-L429">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.:\\" href="#Base.:\\"><code>Base.:\</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">\(s::SparseTensor, o::PyObject, method::String=&quot;SparseLU&quot;)</code></pre><p>Solves the linear equation  <span>$s x = o$</span></p><p><strong>Method</strong></p><p>For square matrices <code>s</code>, one of the following methods is available</p><ul><li><code>SparseLU</code></li><li><code>SparseQR</code></li><li><code>SimplicialLDLT</code></li><li><code>SimplicialLLT</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/sparse.jl#L326-L338">source</a></section></article><h2 id="Operations-1"><a class="docs-heading-anchor" href="#Operations-1">Operations</a><a class="docs-heading-anchor-permalink" href="#Operations-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.argsort-Tuple{PyObject}" href="#ADCME.argsort-Tuple{PyObject}"><code>ADCME.argsort</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">argsort(o::PyObject; 
stable::Bool = false, rev::Bool=false, dims::Integer=-1, name::Union{Nothing,String}=nothing)</code></pre><p>Returns the indices of a tensor that give its sorted order along an axis.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L948-L953">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.batch_matmul-Tuple{PyObject,PyObject}" href="#ADCME.batch_matmul-Tuple{PyObject,PyObject}"><code>ADCME.batch_matmul</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">batch_matmul(o1::PyObject, o2::PyObject)</code></pre><p>Computes <code>o1[i,:,:] * o2[i, :]</code> or <code>o1[i,:,:] * o2[i, :, :]</code> for each index <code>i</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L74-L78">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.clip-Tuple{Union{Array{Any,N} where N, Array{PyObject,N} where N},Any,Any,Vararg{Any,N} where N}" href="#ADCME.clip-Tuple{Union{Array{Any,N} where N, Array{PyObject,N} where N},Any,Any,Vararg{Any,N} where N}"><code>ADCME.clip</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">clip(o::Union{Array{Any}, Array{PyObject}}, vmin, vmax, args...;kwargs...)</code></pre><p>Clips the values of <code>o</code> to the range [<code>vmin</code>, <code>vmax</code>]</p><p><strong>Example</strong></p><pre><code class="language-julia">a = constant(3.0)
a = clip(a, 1.0, 2.0)
b = constant(rand(3))
b = clip(b, 0.5, 1.0)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L680-L692">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.cvec-Tuple{PyObject}" href="#ADCME.cvec-Tuple{PyObject}"><code>ADCME.cvec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">rvec(o::PyObject; kwargs...)</code></pre><p>Vectorizes the tensor <code>o</code> to a column vector, assuming column major.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L420-L424">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.pmap-Tuple{Function,Union{PyObject, Array{PyObject,N} where N}}" href="#ADCME.pmap-Tuple{Function,Union{PyObject, Array{PyObject,N} where N}}"><code>ADCME.pmap</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">pmap(fn::Function, o::Union{Array{PyObject}, PyObject})</code></pre><p>Parallel for loop. There should be no data dependency between different iterations.</p><p><strong>Example</strong></p><pre><code class="language-julia">x = constant(ones(10))
y1 = pmap(x-&gt;2.0*x, x)
y2 = pmap(x-&gt;x[1]+x[2], [x,x])
y3 = pmap(1:10, x) do z
    i = z[1]
    xi = z[2]
    xi + cast(Float64, i)
end
run(sess, y1)
run(sess, y2)
run(sess, y3)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L796-L815">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.rvec-Tuple{PyObject}" href="#ADCME.rvec-Tuple{PyObject}"><code>ADCME.rvec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">rvec(o::PyObject; kwargs...)</code></pre><p>Vectorizes the tensor <code>o</code> to a row vector, assuming row major.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L402-L406">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.set_shape-Union{Tuple{N}, Tuple{PyObject,Union{Tuple{Vararg{Integer,N}}, Array{#s196,N} where N where #s196&lt;:Integer}}} where N" href="#ADCME.set_shape-Union{Tuple{N}, Tuple{PyObject,Union{Tuple{Vararg{Integer,N}}, Array{#s196,N} where N where #s196&lt;:Integer}}} where N"><code>ADCME.set_shape</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">set_shape(o::PyObject, s::Union{Array{&lt;:Integer}, Tuple{Vararg{&lt;:Integer, N}}}) where N
set_shape(o::PyObject, s::Integer...)</code></pre><p>Sets the shape of <code>o</code> to <code>s</code>. <code>s</code> must be the actual shape of <code>o</code>. This function is used to convert a  tensor with unknown dimensions to a tensor with concrete dimensions. </p><p><strong>Example</strong></p><pre><code class="language-julia">a = placeholder(Float64, shape=[nothing, 10])
b = set_shape(a, 3, 10)
run(sess, b, a=&gt;rand(3,10)) # OK 
run(sess, b, a=&gt;rand(5,10)) # Error
run(sess, b, a=&gt;rand(10,3)) # Error</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L190-L205">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.topk" href="#ADCME.topk"><code>ADCME.topk</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">topk(o::PyObject, k::Union{PyObject,Integer}=1;
    sorted::Bool=true, name::Union{Nothing,String}=nothing)</code></pre><p>Finds values and indices of the <code>k</code> largest entries for the last dimension. If <code>sorted=true</code> the resulting k elements will be sorted by the values in descending order.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L935-L941">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.vector-Union{Tuple{T}, Tuple{Union{PyObject, StepRange, UnitRange, Array{T,N} where N},Union{PyObject, Array{Float64,N} where N},Union{Int64, PyObject}}} where T&lt;:Integer" href="#ADCME.vector-Union{Tuple{T}, Tuple{Union{PyObject, StepRange, UnitRange, Array{T,N} where N},Union{PyObject, Array{Float64,N} where N},Union{Int64, PyObject}}} where T&lt;:Integer"><code>ADCME.vector</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">vector(i::Union{Array{T}, PyObject, UnitRange, StepRange}, v::Union{Array{Float64},PyObject},s::Union{Int64,PyObject})</code></pre><p>Returns a vector <code>V</code> with length <code>s</code> such that</p><pre><code class="language-none">V[i] = v</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L868-L875">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.vec-Tuple{PyObject}" href="#Base.vec-Tuple{PyObject}"><code>Base.vec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">vec(o::PyObject;kwargs...)</code></pre><p>Vectorizes the tensor <code>o</code> assuming column major. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L438-L442">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.svd-Tuple{PyObject,Vararg{Any,N} where N}" href="#LinearAlgebra.svd-Tuple{PyObject,Vararg{Any,N} where N}"><code>LinearAlgebra.svd</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">svd(o::PyObject, args...; kwargs...)</code></pre><p>Returns a <code>TFSVD</code> structure which holds the following data structures</p><pre><code class="language-julia">S::PyObject
U::PyObject
V::PyObject
Vt::PyObject</code></pre><p>We have the equality <span>$o = USV&#39;$</span></p><p><strong>Example</strong></p><pre><code class="language-julia">A = rand(10,20)
r = svd(constant(A))
A2 = r.U*diagm(r.S)*r.Vt # The value of `A2` should be equal to `A`</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L722-L741">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.map-Tuple{Function,Union{PyObject, Array{PyObject,N} where N}}" href="#Base.map-Tuple{Function,Union{PyObject, Array{PyObject,N} where N}}"><code>Base.map</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">map(fn::Function, o::Union{Array{PyObject},PyObject};
kwargs...)</code></pre><p>Applies <code>fn</code> to each element of <code>o</code>. </p><ul><li><code>o</code>∈<code>Array{PyObject}</code> : returns <code>[fn(x) for x in o]</code></li><li><code>o</code>∈PyObject : splits <code>o</code> according to the first dimension and then applies <code>fn</code>. </li></ul><p><strong>Example</strong></p><pre><code class="language-julia">a = constant(rand(10,5))
b = map(x-&gt;sum(x), a) # equivalent to `sum(a, dims=2)`</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>If <code>fn</code> is a multivariate function, we need to specify the output type using <code>dtype</code> keyword. For example, </p><pre><code class="language-julia">a = constant(ones(10))
b = constant(ones(10))
fn = x-&gt;x[1]+x[2]
c = map(fn, [a, b], dtype=Float64)</code></pre></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L767-L789">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.reshape-Union{Tuple{N}, Tuple{PyObject,Union{Tuple{Vararg{Integer,N}}, Array{#s196,N} where N where #s196&lt;:Integer}}} where N" href="#Base.reshape-Union{Tuple{N}, Tuple{PyObject,Union{Tuple{Vararg{Integer,N}}, Array{#s196,N} where N where #s196&lt;:Integer}}} where N"><code>Base.reshape</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">reshape(o::PyObject, s::Union{Array{&lt;:Integer}, Tuple{Vararg{&lt;:Integer, N}}}) where N 
reshape(o::PyObject, s::Integer; kwargs...)
reshape(o::PyObject, m::Integer, n::Integer; kwargs...)
reshape(o::PyObject, ::Colon, n::Integer)
reshape(o::PyObject, n::Integer, ::Colon)</code></pre><p>Reshapes the tensor. <code>reshape</code> is compatible with </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L169-L177">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.sort-Tuple{PyObject}" href="#Base.sort-Tuple{PyObject}"><code>Base.sort</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Base.:sort(o::PyObject; 
rev::Bool=false, dims::Integer=-1, name::Union{Nothing,String}=nothing)</code></pre><p>Sort a multidimensional array <code>o</code> along the given dimension. </p><ul><li><code>rev</code>: <code>true</code> for DESCENDING and <code>false</code> (default) for ASCENDING</li><li><code>dims</code>: <code>-1</code> for last dimension. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/ops.jl#L917-L924">source</a></section></article><h2 id="IO-1"><a class="docs-heading-anchor" href="#IO-1">IO</a><a class="docs-heading-anchor-permalink" href="#IO-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.Diary" href="#ADCME.Diary"><code>ADCME.Diary</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Diary(suffix::Union{String, Nothing}=nothing)</code></pre><p>Creates a diary at a temporary directory path. It returns a writer and the corresponding directory path</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/io.jl#L138-L142">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.activate" href="#ADCME.activate"><code>ADCME.activate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">activate(sw::Diary, port::Int64=6006)</code></pre><p>Running <a href="#ADCME.Diary"><code>Diary</code></a> at http://localhost:port.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/io.jl#L168-L172">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load" href="#ADCME.load"><code>ADCME.load</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">load(sess::PyObject, file::String, vars::Union{PyObject, Nothing, Array{PyObject}}=nothing, args...; kwargs...)</code></pre><p>Loads the values of variables to the session <code>sess</code> from the file <code>file</code>. If <code>vars</code> is nothing, it loads values to all the trainable variables. See also <a href="#ADCME.save"><code>save</code></a>, <a href="#ADCME.load"><code>load</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/io.jl#L84-L89">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load-Tuple{Diary,String}" href="#ADCME.load-Tuple{Diary,String}"><code>ADCME.load</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">load(sw::Diary, dirp::String)</code></pre><p>Loads <a href="#ADCME.Diary"><code>Diary</code></a> from <code>dirp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/io.jl#L158-L162">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.pload-Tuple{String}" href="#ADCME.pload-Tuple{String}"><code>ADCME.pload</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">pload(file::String)</code></pre><p>Loads a Python objection from <code>file</code>. See also <a href="#ADCME.psave"><code>psave</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/io.jl#L31-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.psave-Tuple{PyObject,String}" href="#ADCME.psave-Tuple{PyObject,String}"><code>ADCME.psave</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">psave(o::PyObject, file::String)</code></pre><p>Saves a Python objection <code>o</code> to <code>file</code>. See also <a href="#ADCME.pload"><code>pload</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/io.jl#L18-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.save" href="#ADCME.save"><code>ADCME.save</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">save(sess::PyObject, file::String, vars::Union{PyObject, Nothing, Array{PyObject}}=nothing, args...; kwargs...)</code></pre><p>Saves the values of <code>vars</code> in the session <code>sess</code>. The result is written into <code>file</code> as a dictionary. If <code>vars</code> is nothing, it saves all the trainable variables. See also <a href="#ADCME.save"><code>save</code></a>, <a href="#ADCME.load"><code>load</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/io.jl#L46-L51">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.save-Tuple{Diary,String}" href="#ADCME.save-Tuple{Diary,String}"><code>ADCME.save</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">save(sw::Diary, dirp::String)</code></pre><p>Saves <a href="#ADCME.Diary"><code>Diary</code></a> to <code>dirp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/io.jl#L149-L153">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.scalar" href="#ADCME.scalar"><code>ADCME.scalar</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">scalar(o::PyObject, name::String)</code></pre><p>Returns a scalar summary object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/io.jl#L178-L182">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.write-Tuple{Diary,Int64,Union{String, Array{String,N} where N}}" href="#Base.write-Tuple{Diary,Int64,Union{String, Array{String,N} where N}}"><code>Base.write</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">write(sw::Diary, step::Int64, cnt::Union{String, Array{String}})</code></pre><p>Writes to <a href="#ADCME.Diary"><code>Diary</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/io.jl#L190-L194">source</a></section></article><h2 id="Optimization-1"><a class="docs-heading-anchor" href="#Optimization-1">Optimization</a><a class="docs-heading-anchor-permalink" href="#Optimization-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.BFGS!" href="#ADCME.BFGS!"><code>ADCME.BFGS!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">BFGS!(value_and_gradients_function::Function, initial_position::Union{PyObject, Array{Float64}}, max_iter::Int64=50, args...;kwargs...)</code></pre><p>Applies the BFGS optimizer to <code>value_and_gradients_function</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/optim.jl#L202-L206">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.BFGS!" href="#ADCME.BFGS!"><code>ADCME.BFGS!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">BFGS!(sess::PyObject, loss::PyObject, max_iter::Int64=15000; 
vars::Array{PyObject}=PyObject[], callback::Union{Function, Nothing}=nothing, kwargs...)</code></pre><p><code>BFGS!</code> is a simplified interface for BFGS optimizer. See also <a href="#ADCME.ScipyOptimizerInterface-Tuple{Any}"><code>ScipyOptimizerInterface</code></a>. <code>callback</code> is a callback function with signature </p><pre><code class="language-julia">callback(vs::Array, iter::Int64, loss::Float64)</code></pre><p><code>vars</code> is an array consisting of tensors and its values will be the input to <code>vs</code>.</p><p><strong>example</strong></p><pre><code class="language-julia">a = Variable(1.0)
loss = (a - 10.0)^2
BFGS!(sess, loss)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/optim.jl#L153-L170">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.BFGS!-Union{Tuple{T}, Tuple{PyObject,PyObject,Union{Nothing, PyObject, Array{T,N} where N},Union{PyObject, Array{PyObject,N} where N}}} where T&lt;:Union{Nothing, PyObject}" href="#ADCME.BFGS!-Union{Tuple{T}, Tuple{PyObject,PyObject,Union{Nothing, PyObject, Array{T,N} where N},Union{PyObject, Array{PyObject,N} where N}}} where T&lt;:Union{Nothing, PyObject}"><code>ADCME.BFGS!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">BFGS!(sess::PyObject, loss::PyObject, grads::Union{Array{T},Nothing,PyObject}, 
    vars::Union{Array{PyObject},PyObject}; kwargs...) where T&lt;:Union{Nothing, PyObject}</code></pre><p>Running BFGS algorithm <span>$\min_{\texttt{vars}} \texttt{loss}(\texttt{vars})$</span> The gradients <code>grads</code> must be provided. Typically, <code>grads[i] = gradients(loss, vars[i])</code>.  <code>grads[i]</code> can exist on different devices (GPU or CPU). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/optim.jl#L546-L554">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.CustomOptimizer-Tuple{Function}" href="#ADCME.CustomOptimizer-Tuple{Function}"><code>ADCME.CustomOptimizer</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">CustomOptimizer(opt::Function, name::String)</code></pre><p>creates a custom optimizer with struct name <code>name</code>. For example, we can integrate <code>Optim.jl</code> with <code>ADCME</code> by  constructing a new optimizer</p><pre><code class="language-julia">CustomOptimizer(&quot;Con&quot;) do f, df, c, dc, x0, nineq, neq, x_L, x_U
    opt = Opt(:LD_MMA, length(x0))
    bd = zeros(length(x0)); bd[end-1:end] = [-Inf, 0.0]
    opt.lower_bounds = bd
    opt.xtol_rel = 1e-4
    opt.min_objective = (x,g)-&gt;(g[:]= df(x); return f(x)[1])
    inequality_constraint!(opt, (x,g)-&gt;( g[:]= dc(x);c(x)[1]), 1e-8)
    (minf,minx,ret) = NLopt.optimize(opt, x0)
    minx
end</code></pre><p>Then we can create an optimizer with </p><pre><code class="language-none">opt = Con(loss, inequalities=[c1], equalities=[c2])</code></pre><p>To trigger the optimization, use</p><pre><code class="language-none">opt.minimize(sess)</code></pre><p>or </p><pre><code class="language-none">minimize(opt, sess)</code></pre><p>Note thanks to the global variable scope of Julia, <code>step_callback</code>, <code>optimizer_kwargs</code> can actually  be passed from Julia environment directly.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/optim.jl#L73-L105">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.NonlinearConstrainedProblem-Union{Tuple{T}, Tuple{Function,Function,Union{Array{Float64,1}, PyObject},Union{PyObject, Array{Float64,N} where N}}} where T&lt;:Real" href="#ADCME.NonlinearConstrainedProblem-Union{Tuple{T}, Tuple{Function,Function,Union{Array{Float64,1}, PyObject},Union{PyObject, Array{Float64,N} where N}}} where T&lt;:Real"><code>ADCME.NonlinearConstrainedProblem</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">NonlinearConstrainedProblem(f::Function, L::Function, θ::PyObject, u0::Union{PyObject, Array{Float64}}; options::Union{Dict{String, T}, Missing}=missing) where T&lt;:Integer</code></pre><p>Computes the gradients <span>$\frac{\partial L}{\partial \theta}$</span></p><div>\[\min \ L(u) \quad \mathrm{s.t.} \ F(\theta, u) = 0\]</div><p><code>u0</code> is the initial guess for the numerical solution <code>u</code>, see <a href="../newton_raphson/#ADCME.newton_raphson"><code>newton_raphson</code></a>.</p><p>Caveats: Assume <code>r, A = f(θ, u)</code> and <code>θ</code> are the unknown parameters, <code>gradients(r, θ)</code> must be defined (backprop works properly)</p><p>Returns: It returns a tuple (<code>L</code>: loss, <code>C</code>: constraints, and <code>Graidents</code>)</p><div>\[\left(L(u), u, \frac{\partial L}{\partial θ}\right)\]</div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/optim.jl#L483-L502">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ScipyOptimizerInterface-Tuple{Any}" href="#ADCME.ScipyOptimizerInterface-Tuple{Any}"><code>ADCME.ScipyOptimizerInterface</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ScipyOptimizerInterface(loss; method=&quot;L-BFGS-B&quot;, options=Dict(&quot;maxiter&quot;=&gt; 15000, &quot;ftol&quot;=&gt;1e-12, &quot;gtol&quot;=&gt;1e-12), kwargs...)</code></pre><p>A simple interface for Scipy Optimizer. See also <a href="#ADCME.ScipyOptimizerMinimize-Tuple{PyObject,PyObject}"><code>ScipyOptimizerMinimize</code></a> and <a href="#ADCME.BFGS!"><code>BFGS!</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/optim.jl#L46-L50">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ScipyOptimizerMinimize-Tuple{PyObject,PyObject}" href="#ADCME.ScipyOptimizerMinimize-Tuple{PyObject,PyObject}"><code>ADCME.ScipyOptimizerMinimize</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ScipyOptimizerMinimize(sess::PyObject, opt::PyObject; kwargs...)</code></pre><p>Minimizes a scalar Tensor. Variables subject to optimization are updated in-place at the end of optimization.</p><p>Note that this method does not just return a minimization Op, unlike <code>minimize</code>; instead it actually performs minimization by executing commands to control a Session https://www.tensorflow.org/api_docs/python/tf/contrib/opt/ScipyOptimizerInterface. See also <a href="#ADCME.ScipyOptimizerInterface-Tuple{Any}"><code>ScipyOptimizerInterface</code></a> and <a href="#ADCME.BFGS!"><code>BFGS!</code></a>.</p><ul><li>feed_dict: A feed dict to be passed to calls to session.run.</li><li>fetches: A list of Tensors to fetch and supply to loss_callback as positional arguments.</li><li>step_callback: A function to be called at each optimization step; arguments are the current values of all optimization variables flattened into a single vector.</li><li>loss_callback: A function to be called every time the loss and gradients are computed, with evaluated fetches supplied as positional arguments.</li><li>run_kwargs: kwargs to pass to session.run.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/optim.jl#L54-L68">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.newton_raphson-Union{Tuple{T}, Tuple{Function,Union{PyObject, Array}}, Tuple{Function,Union{PyObject, Array},Union{Missing, PyObject, Array{#s196,N} where N where #s196&lt;:Real}}} where T&lt;:Real" href="#ADCME.newton_raphson-Union{Tuple{T}, Tuple{Function,Union{PyObject, Array}}, Tuple{Function,Union{PyObject, Array},Union{Missing, PyObject, Array{#s196,N} where N where #s196&lt;:Real}}} where T&lt;:Real"><code>ADCME.newton_raphson</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">newton_raphson(f::Function, u::Union{Array,PyObject}, θ::Union{Missing,PyObject}; options::Union{Dict{String, T}, Missing}=missing)</code></pre><p>Newton Raphson solver for solving a nonlinear equation.  <code>f</code> has the signature </p><ul><li><code>f(θ::Union{Missing,PyObject}, u::PyObject)-&gt;(r::PyObject, A::Union{PyObject,SparseTensor})</code> (if <code>linesearch</code> is off)</li><li><code>f(θ::Union{Missing,PyObject}, u::PyObject)-&gt;(fval::PyObject, r::PyObject, A::Union{PyObject,SparseTensor})</code> (if <code>linesearch</code> is on)</li></ul><p>where <code>r</code> is the residual and <code>A</code> is the Jacobian matrix; in the case where <code>linesearch</code> is on, the function value <code>fval</code> must also be supplied. <code>θ</code> are external parameters. <code>u0</code> is the initial guess for <code>u</code> <code>options</code>:</p><ul><li><code>max_iter</code>: maximum number of iterations (default=100)</li><li><code>verbose</code>: whether details are printed (default=false)</li><li><code>rtol</code>: relative tolerance for termination (default=1e-12)</li><li><code>tol</code>: absolute tolerance for termination (default=1e-12)</li><li><code>LM</code>: a float number, Levenberg-Marquardt modification <span>$x^{k+1} = x^k - (J^k + \mu^k)^{-1}g^k$</span> (default=0.0)</li><li><code>linesearch</code>: whether linesearch is used (default=false)</li></ul><p>Currently, the backtracing algorithm is implemented. The parameters for <code>linesearch</code> are also supplied via <code>options</code></p><ul><li><code>ls_c1</code>: stop criterion, <span>$f(x^k) &lt; f(0) + \alpha c_1  f&#39;(0)$</span></li><li><code>ls_ρ_hi</code>: the new step size <span>$\alpha_1\leq \rho_{hi}\alpha_0$</span> </li><li><code>ls_ρ_lo</code>: the new step size <span>$\alpha_1\geq \rho_{lo}\alpha_0$</span> </li><li><code>ls_iterations</code>: maximum number of iterations for linesearch</li><li><code>ls_maxstep</code>: maximum allowable steps</li><li><code>ls_αinitial</code>: initial guess for the step size <span>$\alpha$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/optim.jl#L291-L318">source</a></section></article><h2 id="Neural-Networks-1"><a class="docs-heading-anchor" href="#Neural-Networks-1">Neural Networks</a><a class="docs-heading-anchor-permalink" href="#Neural-Networks-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae" href="#ADCME.ae"><code>ADCME.ae</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ae(x::PyObject, output_dims::Array{Int64}, scope::String = &quot;default&quot;;
    activation::Union{Function,String} = &quot;tanh&quot;)</code></pre><p>Creates a neural network with intermediate numbers of neurons <code>output_dims</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/layers.jl#L58-L63">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae-Tuple{Union{PyObject, Array{Float64,N} where N},Array{Int64,N} where N,Union{PyObject, Array{Float64,N} where N}}" href="#ADCME.ae-Tuple{Union{PyObject, Array{Float64,N} where N},Array{Int64,N} where N,Union{PyObject, Array{Float64,N} where N}}"><code>ADCME.ae</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ae(x::Union{Array{Float64}, PyObject}, output_dims::Array{Int64}, θ::Union{Array{Float64}, PyObject};
activation::Union{Function,String} = &quot;tanh&quot;)</code></pre><p>Creates a neural network with intermediate numbers of neurons <code>output_dims</code>. The weights are given by <code>θ</code></p><p><strong>Example 1: Explicitly construct weights and biases</strong></p><pre><code class="language-julia">x = constant(rand(10,2))
n = ae_num([2,20,20,20,2])
θ = Variable(randn(n)*0.001)
y = ae(x, [20,20,20,2], θ)</code></pre><p><strong>Example 2: Implicitly construct weights and biases</strong></p><pre><code class="language-julia">θ = ae_init([10,20,20,20,2]) 
x = constant(rand(10,10))
y = ae(x, [20,20,20,2], θ)</code></pre><p>See also <a href="#ADCME.ae_num-Tuple{Array{Int64,N} where N}"><code>ae_num</code></a>, <a href="#ADCME.ae_init-Tuple{Array{Int64,N} where N}"><code>ae_init</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/layers.jl#L87-L109">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae_init-Tuple{Array{Int64,N} where N}" href="#ADCME.ae_init-Tuple{Array{Int64,N} where N}"><code>ADCME.ae_init</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ae_init(output_dims::Array{Int64}; T::Type=Float64, method::String=&quot;xavier&quot;)</code></pre><p>Return the initial weights and bias values by TensorFlow as a vector. Three types of  random initializers are provided</p><ul><li><code>xavier</code> (default). It is useful for <code>tanh</code> fully connected neural network. </li></ul><div>\[W^l_i \sim \sqrt{\frac{1}{n_{l-1}}}\]</div><ul><li><code>xavier_avg</code>. A variant of <code>xavier</code></li></ul><div>\[W^l_i \sim \sqrt{\frac{2}{n_l + n_{l-1}}}\]</div><ul><li><code>he</code>. This is the activation aware initialization of weights and helps mitigate the problem</li></ul><p>of vanishing/exploding gradients. </p><div>\[W^l_i \sim \sqrt{\frac{2}{n_{l-1}}}\]</div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/layers.jl#L151-L170">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae_num-Tuple{Array{Int64,N} where N}" href="#ADCME.ae_num-Tuple{Array{Int64,N} where N}"><code>ADCME.ae_num</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ae_num(output_dims::Array{Int64})</code></pre><p>Estimates the number of weights and biases for the neural network. Note the first dimension should be the feature dimension (this is different from <a href="#ADCME.ae"><code>ae</code></a> since in <code>ae</code> the feature dimension can be inferred), and the last dimension should be the output dimension. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/layers.jl#L194-L200">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae_to_code-Tuple{String,String}" href="#ADCME.ae_to_code-Tuple{String,String}"><code>ADCME.ae_to_code</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ae_to_code(file::String, scope::String; activation::String = &quot;tanh&quot;)</code></pre><p>Return the code string from the feed-forward neural network data in <code>file</code>. Usually we can immediately evaluate  the code string into Julia session by </p><pre><code class="language-julia">eval(Meta.parse(s))</code></pre><p>If <code>activation</code> is not specified, <code>tanh</code> is the default. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/layers.jl#L238-L247">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.bn-Tuple" href="#ADCME.bn-Tuple"><code>ADCME.bn</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">bn(args...;center = true, scale=true, kwargs...)</code></pre><p><code>bn</code> accepts a keyword parameter <code>is_training</code>. </p><p><strong>Example</strong></p><pre><code class="language-julia">bn(inputs, name=&quot;batch_norm&quot;, is_training=true)</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p><code>bn</code> should be used with <code>control_dependency</code></p><pre><code class="language-julia">update_ops = get_collection(UPDATE_OPS)
control_dependencies(update_ops) do 
    global train_step = AdamOptimizer().minimize(loss)
end </code></pre></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/layers.jl#L314-L331">source</a></section></article><h2 id="Generative-Neural-Nets-1"><a class="docs-heading-anchor" href="#Generative-Neural-Nets-1">Generative Neural Nets</a><a class="docs-heading-anchor-permalink" href="#Generative-Neural-Nets-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.GAN" href="#ADCME.GAN"><code>ADCME.GAN</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GAN(dat::PyObject, 
    generator::Function, 
    discriminator::Function,
    loss::Union{String, Function, Missing}=missing; 
    latent_dim::Union{Missing, Int64}=missing, 
    batch_size::Union{Missing, Int64}=missing)</code></pre><p>Creates a GAN instance. </p><ul><li><code>dat</code> <span>$\in \mathbb{R}^{n\times d}$</span> is the training data for the GAN, where <span>$n$</span> is the number of training data, and <span>$d$</span> is the dimension per training data.</li><li><code>generator</code><span>$:\mathbb{R}^{d&#39;} \rightarrow \mathbb{R}^d$</span> is the generator function, <span>$d&#39;$</span> is the hidden dimension.</li><li><code>discriminator</code><span>$:\mathbb{R}^{d} \rightarrow \mathbb{R}$</span> is the discriminator function. </li><li><code>loss</code> is the loss function. See <a href="#ADCME.klgan-Tuple{GAN}"><code>klgan</code></a>, <a href="#ADCME.rklgan-Tuple{GAN}"><code>rklgan</code></a>, <a href="#ADCME.wgan-Tuple{GAN}"><code>wgan</code></a>, <a href="#ADCME.lsgan-Tuple{GAN}"><code>lsgan</code></a> for examples.</li><li><code>latent_dim</code> (default=<span>$d$</span>, the same as output dimension) is the latent dimension.</li><li><code>batch_size</code> (default=32) is the batch size in training.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/gan.jl#L34-L50">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.jsgan-Tuple{GAN}" href="#ADCME.jsgan-Tuple{GAN}"><code>ADCME.jsgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">jsgan(gan::GAN)</code></pre><p>Computes the vanilla GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/gan.jl#L84-L88">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.klgan-Tuple{GAN}" href="#ADCME.klgan-Tuple{GAN}"><code>ADCME.klgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">klgan(gan::GAN)</code></pre><p>Computes the KL-divergence GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/gan.jl#L70-L74">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.lsgan-Tuple{GAN}" href="#ADCME.lsgan-Tuple{GAN}"><code>ADCME.lsgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">lsgan(gan::GAN)</code></pre><p>Computes the least square GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/gan.jl#L126-L130">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.predict-Tuple{GAN,Union{PyObject, Array}}" href="#ADCME.predict-Tuple{GAN,Union{PyObject, Array}}"><code>ADCME.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">predict(gan::GAN, input::Union{PyObject, Array})</code></pre><p>Predicts the GAN <code>gan</code> output given input <code>input</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/gan.jl#L182-L186">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.rklgan-Tuple{GAN}" href="#ADCME.rklgan-Tuple{GAN}"><code>ADCME.rklgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">rklgan(gan::GAN)</code></pre><p>Computes the reverse KL-divergence GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/gan.jl#L112-L116">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.sample-Tuple{GAN,Int64}" href="#ADCME.sample-Tuple{GAN,Int64}"><code>ADCME.sample</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sample(gan::GAN, n::Int64)</code></pre><p>Samples <code>n</code> instances from <code>gan</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/gan.jl#L166-L170">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.wgan-Tuple{GAN}" href="#ADCME.wgan-Tuple{GAN}"><code>ADCME.wgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">wgan(gan::GAN)</code></pre><p>Computes the Wasserstein GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/gan.jl#L98-L102">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.build!-Tuple{GAN}" href="#ADCME.build!-Tuple{GAN}"><code>ADCME.build!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">build!(gan::GAN)</code></pre><p>Builds the GAN instances. This function returns <code>gan</code> for convenience.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/gan.jl#L141-L145">source</a></section></article><h2 id="Tools-1"><a class="docs-heading-anchor" href="#Tools-1">Tools</a><a class="docs-heading-anchor-permalink" href="#Tools-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.compile_op-Tuple{String}" href="#ADCME.compile_op-Tuple{String}"><code>ADCME.compile_op</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">compile_op(oplibpath::String; check::Bool=false)</code></pre><p>Compile the library operator by force.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/extra.jl#L52-L56">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.customop" href="#ADCME.customop"><code>ADCME.customop</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">customop(simple::Bool=false)</code></pre><p>Create a new custom operator. If <code>simple=true</code>, the custom operator only supports CPU and does not have gradients. </p><p><strong>Example</strong></p><pre><code class="language-julia-repl">julia&gt; customop() # create an editable `customop.txt` file
[ Info: Edit custom_op.txt for custom operators
julia&gt; customop() # after editing `customop.txt`, call it again to generate interface files.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/extra.jl#L224-L236">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.install-Tuple{String}" href="#ADCME.install-Tuple{String}"><code>ADCME.install</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">install(s::String; force::Bool = false)</code></pre><p>Install a custom operator via URL. <code>s</code> can be</p><ul><li>A URL. ADCME will download the directory through <code>git</code></li><li>A string. ADCME will search for the associated package on https://github.com/ADCMEMarket</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/extra.jl#L299-L305">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load_op-Tuple{String,String}" href="#ADCME.load_op-Tuple{String,String}"><code>ADCME.load_op</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">load_op(oplibpath::String, opname::String)</code></pre><p>Loads the operator <code>opname</code> from library <code>oplibpath</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/extra.jl#L79-L83">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load_op_and_grad-Tuple{String,String}" href="#ADCME.load_op_and_grad-Tuple{String,String}"><code>ADCME.load_op_and_grad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">load_op_and_grad(oplibpath::String, opname::String; multiple::Bool=false)</code></pre><p>Loads the operator <code>opname</code> from library <code>oplibpath</code>; gradients are also imported.  If <code>multiple</code> is true, the operator is assumed to have multiple outputs. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/extra.jl#L109-L114">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load_system_op" href="#ADCME.load_system_op"><code>ADCME.load_system_op</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">load_system_op(s::String, oplib::String, grad::Bool=true)</code></pre><p>Loads custom operator from CustomOps directory (shipped with ADCME instead of TensorFlow) For example </p><pre><code class="language-none">s = &quot;SparseOperator&quot;
oplib = &quot;libSO&quot;
grad = true</code></pre><p>this will direct Julia to find library <code>CustomOps/SparseOperator/libSO.dylib</code> on MACOSX</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/extra.jl#L160-L171">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.test_jacobian-Tuple{Function,Array{Float64,N} where N}" href="#ADCME.test_jacobian-Tuple{Function,Array{Float64,N} where N}"><code>ADCME.test_jacobian</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">test_jacobian(f::Function, x0::Array{Float64}; scale::Float64 = 1.0)</code></pre><p>Testing the gradients of a vector function <code>f</code>: <code>y, J = f(x)</code> where <code>y</code> is a vector output and <code>J</code> is the Jacobian.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/extra.jl#L267-L272">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.xavier_init" href="#ADCME.xavier_init"><code>ADCME.xavier_init</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">xavier_init(size, dtype=Float64)</code></pre><p>Returns a matrix of size <code>size</code> and its values are from Xavier initialization. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/extra.jl#L12-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.compile-Tuple{String}" href="#ADCME.compile-Tuple{String}"><code>ADCME.compile</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">compile(s::String)</code></pre><p>Compiles the library <code>s</code> by force.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/3352e418bd1a4940fa7ea894fa786204601339d7/src/extra.jl#L199-L203">source</a></section></article><h2 id="Misc-1"><a class="docs-heading-anchor" href="#Misc-1">Misc</a><a class="docs-heading-anchor-permalink" href="#Misc-1" title="Permalink"></a></h2></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../apps_ad/">« Intelligent Automatic Differentiation</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 24 February 2020 22:13">Monday 24 February 2020</span>. Using Julia version 1.3.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
