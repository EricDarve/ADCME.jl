<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Calibrating Multivariate Lévy Processes with Neural Networks · ADCME</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../"><img class="logo" src="../assets/logo.png" alt="ADCME logo"/></a><h1>ADCME</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Overview</a></li><li><a class="toctext" href="../inverse_modeling/">Inverse Modeling</a></li><li><span class="toctext">Manual</span><ul><li><a class="toctext" href="../array/">Tensor Operations</a></li><li><a class="toctext" href="../sparse/">Sparse Linear Algebra</a></li><li><a class="toctext" href="../newton_raphson/">Newton Raphson</a></li></ul></li><li><span class="toctext">Resources</span><ul><li><a class="toctext" href="../customop/">Custom Operators</a></li><li><a class="toctext" href="../while_loop/">While Loops</a></li><li><a class="toctext" href="../julia_customop/">Julia Custom Operators</a></li><li><a class="toctext" href="../pytorchnn/">Neural Network in C++</a></li><li><a class="toctext" href="../extra/">Miscellaneous Tools</a></li></ul></li><li><span class="toctext">Applications</span><ul><li><a class="toctext" href="../apps_ana/">Adversarial Numerical Analysis</a></li><li class="current"><a class="toctext" href>Calibrating Multivariate Lévy Processes with Neural Networks</a><ul class="internal"></ul></li><li><a class="toctext" href="../apps_constitutive_law/">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></li></ul></li><li><a class="toctext" href="../api/">API Reference</a></li></ul></nav><article id="docs"><header><nav><ul><li>Applications</li><li><a href>Calibrating Multivariate Lévy Processes with Neural Networks</a></li></ul><a class="edit-page" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/apps_levy.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Calibrating Multivariate Lévy Processes with Neural Networks</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Calibrating-Multivariate-Lévy-Processes-with-Neural-Networks-1" href="#Calibrating-Multivariate-Lévy-Processes-with-Neural-Networks-1">Calibrating Multivariate Lévy Processes with Neural Networks</a></h1><hr/><p>Kailai Xu and Eric Darve. &quot;<a href="https://arxiv.org/abs/1812.08883">Calibrating Multivariate Lévy Processes with Neural Networks</a>&quot; </p><p><a href="https://github.com/kailaix/LevyNN.jl">Project Website</a></p><hr/><p>Calibrating a Lévy process usually requires characterizing its jump distribution. Traditionally this problem can be solved with nonparametric estimation using the empirical characteristic functions (ECF), assuming certain regularity, and results to date are mostly in 1D. For multivariate Lévy processes and less smooth Lévy densities, the problem becomes challenging as ECFs decay slowly and have large uncertainty because of limited observations. We solve this problem by approximating the Lévy density with a parametrized functional form; the characteristic function is then estimated using numerical integration. In our benchmarks, we used deep neural networks and found that they are robust and can capture sharp transitions in the Lévy density. They perform favorably compared to piecewise linear functions and radial basis functions. The methods and techniques developed here apply to many other problems that involve nonparametric estimation of functions embedded in a system model.</p><p>The Lévy process can be described by the Lévy-Khintchine formula</p><p><span>$\phi({\xi}) = \mathbb{E}[e^{\mathrm{i} \langle {\xi}, \mathbf{X}_t \rangle}] =\exp\left[t\left( \mathrm{i} \langle \mathbf{b}, {\xi} \rangle - \frac{1}{2}\langle {\xi}, \mathbf{A}{\xi}\rangle  +\int_{\mathbb{R}^d} \left( e^{\mathrm{i} \langle {\xi}, \mathbf{x}\rangle} - 1 - \mathrm{i} \langle {\xi}, \mathbf{x}\rangle \mathbf{1}_{\|\mathbf{x}\|\leq 1}\right)\nu(d\mathbf{x})\right) \right]$</span></p><p>Here the multivariate Lévy process is described by three parameters: a positive semi-definite matrix <span>$\mathbf{A} = {\Sigma}{\Sigma}^T \in \mathbb{R}^{d\times d}$</span>, where <span>${\Sigma}\in \mathbb{R}^{d\times d}$</span>; a vector <span>$\mathbf{b}\in \mathbb{R}^d$</span>; and a measure <span>$\nu\in \mathbb{R}^d\backslash\{\mathbf{0}\}$</span>. </p><p>Given a sample path <span>$\mathbf{X}_{i\Delta t}$</span>, <span>$i=1,2,3,\ldots$</span>, we focus on estimating <span>$\mathbf{b}$</span>, <span>$\mathbf{A}$</span> and <span>$\nu$</span>. In this work, we focus on the functional inverse problem–estimate <span>$\nu$</span>–and assume <span>$\mathbf{b}=0,\mathbf{A}=0$</span>. The idea is</p><ul><li>The Lévy density is approximated by a parametric functional form–-such as piecewise linear functions–-with parameters <span>$\theta$</span>,</li></ul><div>\[    \nu(\mathbf{x}) \approx \nu_{\theta}(\mathbf{x})\]</div><ul><li>The characteristic function is approximated by numerical integration </li></ul><div>\[\phi({\xi})\approx    \phi_{\theta}({\xi}) := \exp\left[ \Delta t \sum_{i=1}^{n_q} \left(e^{\mathrm{i} \langle{\xi}, \mathbf{x}_i \rangle}-1-\mathrm{i}\langle{\xi}, \mathbf{x}_i \rangle\mathbf{1}_{\|\mathbf{x}_i\|\leq 1}  \right)\nu_{\theta}(\mathbf{x}_i) w_i \right]\]</div><p>where <span>$\{(\mathbf{x}_i, w_i)\}_{i=1}^{n_q}$</span> are quadrature nodes and weights.</p><ul><li>The empirical characteristic functions are computed given observations <span>$\{\mathbf{X}_{i\Delta t}\}_{i=0}^n$</span></li></ul><div>\[\hat\phi_n({\xi}) := \frac{1}{n}\sum_{i=1}^n \exp(\mathrm{i}\langle {\xi}, \mathbf{X}_{i\Delta t}-\mathbf{X}_{(i-1)\Delta t}\rangle ),\  {\xi} \in \mathbb{R}^d\]</div><ul><li>Solve the following optimization problem with a gradient based method. Here <span>$\{{\xi}_i \}_{i=1}^m$</span> are collocation points depending on the data. </li></ul><div>\[\min_{\theta}\frac{1}{m} \sum_{i=1}^m \|\hat\phi_n({\xi}_i)-\phi_{\theta}({\xi}_i)  \|^2\]</div><p>We show the schematic description of the method and some results on calibrating a discontinuous Lévy density function <span>$\nu$</span>. </p><p><img src="../asset/levy.png" alt="image-20191031200808697"/></p><footer><hr/><a class="previous" href="../apps_ana/"><span class="direction">Previous</span><span class="title">Adversarial Numerical Analysis</span></a><a class="next" href="../apps_constitutive_law/"><span class="direction">Next</span><span class="title">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</span></a></footer></article></body></html>
