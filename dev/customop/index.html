<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Custom Operators · ADCME</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>ADCME</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Getting Started</a></li><li><span class="toctext">Additional Tools</span><ul><li><a class="toctext" href="../extra/">Additional Tools</a></li><li class="current"><a class="toctext" href>Custom Operators</a><ul class="internal"></ul></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Additional Tools</li><li><a href>Custom Operators</a></li></ul><a class="edit-page" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/customop.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Custom Operators</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Custom-Operators-1" href="#Custom-Operators-1">Custom Operators</a></h1><p>Custom operators are ways to add missing features in <code>ADCME</code>. Typically users do not have to worry about custom operators. However, in the following situation custom opreators might be very useful</p><ul><li>Direct implementation in <code>ADCME</code> is inefficient (bottleneck). </li><li>There are legacy codes users want to reuse, such as GPU-accelerated codes. </li><li>Special acceleration techniques such as checkpointing scheme. </li></ul><p>In the following, we present an example of implementing the sparse solver custom operator for <span>$Ax=b$</span>.</p><p><strong>Input</strong>: row vector <code>ii</code>, column vector<code>jj</code> and value vector <code>vv</code> for the sparse coefficient matrix; row vector <code>kk</code> and value vector <code>ff</code>, matrix dimension <span>$d$</span></p><p><strong>Output</strong>: solution vector <span>$u$</span></p><ol><li><p><strong>Create and modify the template file</strong></p><p>The following command helps create the wrapper</p><pre><code class="language-julia">customop()</code></pre><p>There will be a <code>custom_op.txt</code> in the current directory. Modify the template file </p><pre><code class="language-txt">MySparseSolver
int32 ii(?)
int32 jj(?)
double vv(?)
int32 kk(?)
double ff(?)
int32 d()
double u(?) -&gt; output</code></pre><p>The first line is the name of the operator. It should always be in the camel case. </p><p>The 2nd to the 7th lines specify the input arguments, the signature is <code>type</code>+<code>variable name</code>+<code>shape</code>. For the shape, <code>()</code> corresponds to a scalar, <code>(?)</code> to a vector and <code>(?,?)</code> to a matrix. </p><p>The last line is the output, denoted by <code>-&gt; output</code>. Note there must be a space before and after <code>-&gt;</code>. </p><p>The following types are accepted: <code>int32</code>, <code>int64</code>, <code>double</code>, <code>float</code>, <code>string</code>, <code>bool</code>. The name of the arguments must all be in <em>lower cases</em>. </p></li></ol><ol><li><p><strong>Implement core codes</strong></p><p>Run <code>customop()</code> again and there will be <code>CMakeLists.txt</code>, <code>gradtest.jl</code>, <code>MySparseSolver.cpp</code> appearing in the current directory. <code>MySparseSolver.cpp</code> is the main wrapper for the codes and <code>gradtest.jl</code> is used for testing the operator and its gradients. <code>CMakeLists.txt</code> is the file for compilation. </p><p>Create a new file <code>MySparseSolver.h</code> and implement both the forward simulation and backward simulation (gradients)</p><pre><code class="language-cpp">#include &lt;eigen3/Eigen/Sparse&gt;
#include &lt;eigen3/Eigen/SparseLU&gt;
#include &lt;vector&gt;
#include &lt;iostream&gt;
using namespace std;
typedef Eigen::SparseMatrix&lt;double&gt; SpMat; // declares a column-major sparse matrix type of double
typedef Eigen::Triplet&lt;double&gt; T;

SpMat A;

void forward(double *u, const int *ii, const int *jj, const double *vv, int nv, const int *kk, const double *ff,int nf,  int d){
    vector&lt;T&gt; triplets;
    Eigen::VectorXd rhs(d); rhs.setZero();
    for(int i=0;i&lt;nv;i++){
      triplets.push_back(T(ii[i]-1,jj[i]-1,vv[i]));
    }
    for(int i=0;i&lt;nf;i++){
      rhs[kk[i]-1] += ff[i];
    }
    A.resize(d, d);
    A.setFromTriplets(triplets.begin(), triplets.end());
    auto C = Eigen::MatrixXd(A);
    Eigen::SparseLU&lt;SpMat&gt; solver;
    solver.analyzePattern(A);
    solver.factorize(A);
    auto x = solver.solve(rhs);
    for(int i=0;i&lt;d;i++) u[i] = x[i];
}

void backward(double *grad_vv, const double *grad_u, const int *ii, const int *jj, const double *u, int nv, int d){
    Eigen::VectorXd g(d);
    for(int i=0;i&lt;d;i++) g[i] = grad_u[i];
    auto B = A.transpose();
    Eigen::SparseLU&lt;SpMat&gt; solver;
    solver.analyzePattern(B);
    solver.factorize(B);
    auto x = solver.solve(g);
    // cout &lt;&lt; x &lt;&lt; endl;
    for(int i=0;i&lt;nv;i++) grad_vv[i] = 0.0;
    for(int i=0;i&lt;nv;i++){
      grad_vv[i] -= x[ii[i]-1]*u[jj[i]-1];
    }
}</code></pre><p>In this implementation we have used <code>Eigen</code> library for solving sparse matrix. Other choices are also possible, such as algebraic multigrid methods. Note here for convenience we have created a global variable <code>SpMat A;</code>. This is not recommend if you want to run the code concurrently. </p></li><li><p><strong>Compile</strong></p><p>It is recommend that you use the <code>cmake</code>, <code>make</code> and <code>gcc</code> provided by <code>ADCME</code>. </p></li></ol><table><tr><th style="text-align: right">Variable</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>ADCME.CXX</code></td><td style="text-align: right">C++ Compiler</td></tr><tr><td style="text-align: right"><code>ADCME.CC</code></td><td style="text-align: right">C Compiler</td></tr><tr><td style="text-align: right"><code>ADCME.TFLIB</code></td><td style="text-align: right"><code>libtensorflow_framework.so</code> location</td></tr><tr><td style="text-align: right"><code>ADCME.CMAKE</code></td><td style="text-align: right">Cmake binary location</td></tr><tr><td style="text-align: right"><code>ADCME.MAKE</code></td><td style="text-align: right">Make binary location</td></tr></table><pre><code class="language-none">A simple way is to set the environment by
```bash
export CC=&lt;CC&gt;
export CXX=&lt;CXX&gt;
alias cmake=&lt;CMAKE&gt;
alias make=&lt;MAKE&gt;
```
The values such as `&lt;CC&gt;` are obtained from the last table. Run the following command</code></pre><p><code>bash    mkdir build    cd build    cmake ..    make -j</code></p><p>Based on your operation system, you will create <code>libMySparseSolver.{so,dylib,dll}</code>. This will be the dynamic library to link in <code>TensorFlow</code>. </p><ol><li><p><strong>Test</strong></p><p>Finally, you could use <code>gradtest.jl</code> to test the operator and its gradients (specify appropriate data in <code>gradtest.jl</code> first). If you implement the gradients correctly, you will be able to obtain first order convergence for finite difference and second order convergence for automatic differentiation. </p><p><img src="../asset/custom_op.png" alt="custom_op"/></p></li></ol><footer><hr/><a class="previous" href="../extra/"><span class="direction">Previous</span><span class="title">Additional Tools</span></a></footer></article></body></html>
