<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Inverse Modeling Recipe · ADCME</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="ADCME logo"/></a><div class="docs-package-name"><span class="docs-autofit">ADCME</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../tutorial/">Overview</a></li><li><a class="tocitem" href="../tu_whatis/">What is ADCME? Computational Graph, Automatic Differentiation &amp; TensorFlow</a></li><li><a class="tocitem" href="../tu_basic/">ADCME Basics: Tensor, Type, Operator, Session &amp; Kernel</a></li><li><a class="tocitem" href="../tu_sparse/">Sparse Linear Algebra</a></li><li><a class="tocitem" href="../tu_fd/">Numerical Scheme in ADCME: Finite Difference Example</a></li><li><a class="tocitem" href="../tu_fem/">Numerical Scheme in ADCME: Finite Element Example</a></li><li><a class="tocitem" href="../tu_inv/">Inverse Modeling with ADCME</a></li><li class="is-active"><a class="tocitem" href>Inverse Modeling Recipe</a><ul class="internal"><li><a class="tocitem" href="#Forward-Modeling-1"><span>Forward Modeling</span></a></li><li><a class="tocitem" href="#Inverse-Modeling-1"><span>Inverse Modeling</span></a></li></ul></li><li><a class="tocitem" href="../tu_implicit/">Advanced: Automatic Differentiation for Implicit Operators</a></li></ul></li><li><span class="tocitem">Resources</span><ul><li><a class="tocitem" href="../newton_raphson/">Newton Raphson</a></li><li><a class="tocitem" href="../parallel/">Parallel Computing</a></li><li><a class="tocitem" href="../ode/">PDE/ODE Solvers</a></li><li><a class="tocitem" href="../customop/">Custom Operators</a></li><li><a class="tocitem" href="../global/">Shared Memory Across Kernels</a></li><li><a class="tocitem" href="../julia_customop/">Julia Custom Operators</a></li><li><a class="tocitem" href="../pytorchnn/">Neural Network in C++</a></li><li><a class="tocitem" href="../extra/">Miscellaneous Tools</a></li><li><a class="tocitem" href="../ot/">Optimal Transport</a></li><li><a class="tocitem" href="../resource_manager/">Resource Manager</a></li></ul></li><li><span class="tocitem">Applications</span><ul><li><a class="tocitem" href="../apps/">Overview</a></li><li><a class="tocitem" href="../apps_ana/">Adversarial Numerical Analysis</a></li><li><a class="tocitem" href="../apps_levy/">Calibrating Multivariate Lévy Processes with Neural Networks</a></li><li><a class="tocitem" href="../apps_constitutive_law/">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></li><li><a class="tocitem" href="../apps_ad/">Intelligent Automatic Differentiation</a></li></ul></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorial</a></li><li class="is-active"><a href>Inverse Modeling Recipe</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Inverse Modeling Recipe</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/tu_recipe.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Inverse-Modeling-Recipe-1"><a class="docs-heading-anchor" href="#Inverse-Modeling-Recipe-1">Inverse Modeling Recipe</a><a class="docs-heading-anchor-permalink" href="#Inverse-Modeling-Recipe-1" title="Permalink"></a></h1><p>Here is a tip for inverse modeling using ADCME. </p><h2 id="Forward-Modeling-1"><a class="docs-heading-anchor" href="#Forward-Modeling-1">Forward Modeling</a><a class="docs-heading-anchor-permalink" href="#Forward-Modeling-1" title="Permalink"></a></h2><p>The first step is to implement your forward computation in ADCME. Let&#39;s consider a simple example. Assume that we want to compute a transformation from <span>$\{x_1,x_2, \ldots, x_n\}$</span> to <span>$\{f_\theta(x_1), f_\theta(x_2), \ldots, f_\theta(x_n)\}$</span>, where </p><div>\[f_\theta(x) = a_2\sigma(a_1x+b_1)+b_2\quad \theta=(a_1,b_2,a_2,b_2)\]</div><p>The value <span>$\theta=(1,2,3,4)$</span>. We can code the forward computation as follows</p><pre><code class="language-julia">using ADCME
θ = constant([1.;2.;3.;4.])
x = collect(LinRange(0.0,1.0,10))
f = θ[3]*sigmoid(θ[1]*x+θ[2])+θ[4]

sess = Session(); init(sess)
f0 = run(sess, f)</code></pre><p>We obtained</p><pre><code class="language-text">10-element Array{Float64,1}:
 6.6423912339336475
 6.675935315969742
 6.706682200447601
 6.734800968378825
 6.7604627001561575
 6.783837569144308
 6.805092492614008
 6.824389291376896
 6.841883301751329
 6.8577223804673</code></pre><h2 id="Inverse-Modeling-1"><a class="docs-heading-anchor" href="#Inverse-Modeling-1">Inverse Modeling</a><a class="docs-heading-anchor-permalink" href="#Inverse-Modeling-1" title="Permalink"></a></h2><p>Assume that we want to estimate the target variable <span>$\theta$</span> from observations <span>$\{f_\theta(x_1), f_\theta(x_2), \ldots, f_\theta(x_n)\}$</span>. The inverse modeling is split into 6 steps. Follow the steps one by one</p><ul><li><p><strong>Step 1: Mark the target variable as <code>placeholder</code></strong>. That is, we replace <code>θ = constant([1.;2.;3.;4.])</code> by <code>θ = placeholder([1.;2.;3.;4.])</code>.</p></li><li><p><strong>Step 2: Check that the loss is zero given true values.</strong> The loss function is usually formulated so that it equals zero when we plug the true value to the target variable. </p><p>You should expect <code>0.0</code> using the following codes. </p></li></ul><pre><code class="language-julia">using ADCME
θ = placeholder([1.;2.;3.;4.])
x = collect(LinRange(0.0,1.0,10))
f = θ[3]*sigmoid(θ[1]*x+θ[2])+θ[4]
loss = sum((f - f0)^2)
sess = Session(); init(sess)
@show run(sess, loss)</code></pre><ul><li><strong>Step 3: Use <code>lineview</code> to visualize the landscape</strong>. Assume the initial guess is <span>$\theta_0$</span>, we can use the <code>lineview</code> function from <a href="https://github.com/kailaix/ADCMEKit.jl"><code>ADCMEKit.jl</code></a> package to visualize the landscape from <span>$\theta_0=[0,0,0,0]$</span> to <span>$\theta^*$</span> (true value). This gives us  early confidence  on the correctness of the implementation as well as the difficulty of the optimization problem. You can also use <code>meshview</code>, which shows a 2D landscape but is more expensive to evaluate. </li></ul><pre><code class="language-julia">using ADCME
using ADCMEKit
θ = placeholder([1.;2.;3.;4.])
x = collect(LinRange(0.0,1.0,10))
f = θ[3]*sigmoid(θ[1]*x+θ[2])+θ[4]
loss = sum((f - f0)^2)
sess = Session(); init(sess)
@show run(sess, loss)
lineview(sess, θ, loss, [1.;2.;3.;4.], zeros(4)) # or meshview(sess, θ, loss, [1.;2.;3.;4.])</code></pre><p><img src="../assets/landscape.png" alt="image-20200227233902747"/></p><p>The landscape is very nice (convex and smooth)! That means the optimization should be very easy. </p><ul><li><strong>Step 4: Use <code>gradview</code> to check the gradients.</strong> <code>ADCMEKit.jl</code> also provides <code>gradview</code> which visualizes the gradients at arbitrary points. This helps us to check whether the gradient is implemented correctly. </li></ul><pre><code class="language-julia">using ADCME
using ADCMEKit
θ = placeholder([1.;2.;3.;4.])
x = collect(LinRange(0.0,1.0,10))
f = θ[3]*sigmoid(θ[1]*x+θ[2])+θ[4]
loss = sum((f - f0)^2)
sess = Session(); init(sess)
@show run(sess, loss)
lineview(sess, θ, loss, [1.;2.;3.;4.], zeros(4)) # or meshview(sess, θ, loss, [1.;2.;3.;4.])
gradview(sess, θ, loss, zeros(4))</code></pre><p>​		You should get something like this:</p><p><img src="../assets/custom_op.png" alt/></p><ul><li><strong>Step 5: Change <code>placeholder</code> to <code>Variable</code> and perform optimization!</strong> We use L-BFGS-B optimizer to solve the minimization problem. A useful trick is to multiply the loss function by a large scalar so that the optimizer does not stop early (or reduce the tolerance). </li></ul><pre><code class="language-julia">using ADCME
using ADCMEKit
θ = Variable(zeros(4))
x = collect(LinRange(0.0,1.0,10))
f = θ[3]*sigmoid(θ[1]*x+θ[2])+θ[4]
loss = 1e10*sum((f - f0)^2)
sess = Session(); init(sess)
BFGS!(sess, loss)
run(sess, θ)</code></pre><p>You should get </p><pre><code class="language-bash">4-element Array{Float64,1}:
 1.0000000000008975
 2.0000000000028235
 3.0000000000056493
 3.999999999994123</code></pre><p>That&#39;s exact what we want. </p><ul><li><strong>Step 6: Last but not least, repeat step 3 and step 4 if you get stuck in a local minimum.</strong> Scrutinizing the landscape at the local minimum will give you useful information so you can make educated next step!</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tu_inv/">« Inverse Modeling with ADCME</a><a class="docs-footer-nextpage" href="../tu_implicit/">Advanced: Automatic Differentiation for Implicit Operators »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 29 February 2020 22:45">Saturday 29 February 2020</span>. Using Julia version 1.3.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
