<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>- · ADCME</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>ADCME</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Overview</a></li><li><span class="toctext">Inverse Modeling</span><ul><li><a class="toctext" href="../inverse_modeling/">Overview</a></li></ul></li><li><span class="toctext">Automatic Differentiation</span><ul><li><a class="toctext" href="../four_types/">Forward Operator Types</a></li></ul></li><li><span class="toctext">Resources</span><ul><li><a class="toctext" href="../customop/">Custom Operators</a></li><li><a class="toctext" href="../while_loop/">While Loops</a></li><li><a class="toctext" href="../newton_raphson/">Newton Raphson</a></li><li><a class="toctext" href="../julia_customop/">Julia Custom Operators</a></li><li><a class="toctext" href="../pytorchnn/">Neural Network in C++</a></li><li><a class="toctext" href="../extra/">Miscellaneous Tools</a></li><li><a class="toctext" href="../array/">Array Operations</a></li></ul></li><li><span class="toctext">Applications</span><ul><li><a class="toctext" href="../apps_ana/">Adversarial Numerical Analysis</a></li><li><a class="toctext" href="../apps_levy/">Calibrating Multivariate Lévy Processes with Neural Networks</a></li><li><a class="toctext" href="../apps_constitutive_law/">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></li></ul></li><li><a class="toctext" href="../api/">API Reference</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>-</a></li></ul><a class="edit-page" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/customop_reference_sheet.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>-</span><a class="fa fa-bars" href="#"></a></div></header><h2><a class="nav-anchor" id="Quick-Reference-for-Implementing-Julia-Custom-Operator-in-ADCMAE-1" href="#Quick-Reference-for-Implementing-Julia-Custom-Operator-in-ADCMAE-1">Quick Reference for Implementing Julia Custom Operator in ADCMAE</a></h2><ol><li>Header files</li></ol><pre><code class="language-c">  #include &quot;julia.h&quot;
  #include &quot;Python.h&quot;</code></pre><ol><li>For Python GIL workround</li></ol><pre><code class="language-c">PyGILState_STATE py_threadstate;
py_threadstate = PyGILState_Ensure();
...
PyGILState_Release(py_threadstate);</code></pre><ol><li>Get function from Julia main module </li></ol><pre><code class="language-julia">jl_get_function(jl_main_module, &quot;myfun&quot;);</code></pre><ol><li>C++ to Julia</li></ol><pre><code class="language-julia">jl_value_t *a = jl_box_float64(3.0);
jl_value_t *b = jl_box_float32(3.0f);
jl_value_t *c = jl_box_int32(3);</code></pre><ol><li>Julia to C++</li></ol><pre><code class="language-julia">double ret_unboxed = jl_unbox_float64(ret);
float  ret_unboxed = jl_unbox_float32(ret);
int32  ret_unboxed = jl_unbox_int32(ret);</code></pre><ol><li>C++ Arrays to Julia Arrays</li></ol><pre><code class="language-julia">jl_value_t* array_type = jl_apply_array_type((jl_value_t*)jl_float64_type, 1);
jl_array_t* x          = jl_alloc_array_1d(array_type, 10);</code></pre><p>or for existing arrays</p><pre><code class="language-julia">double *existingArray = (double*)malloc(sizeof(double)*10);
jl_array_t *x = jl_ptr_to_array_1d(array_type, existingArray, 10, 0);</code></pre><ol><li>Julia Arrays to C++ Arrays</li></ol><pre><code class="language-julia">double *xData = (double*)jl_array_data(x);</code></pre><ol><li>Call Julia Functions</li></ol><pre><code class="language-julia">jl_array_t *y = (jl_array_t*)jl_call1(func, (jl_value_t*)x);
jl_value_t *jl_call(jl_function_t *f, jl_value_t **args, int32_t nargs)</code></pre><ol><li>Gabage collection</li></ol><pre><code class="language-julia">jl_value_t **args;
JL_GC_PUSHARGS(args, 2); // args can now hold 2 `jl_value_t*` objects
args[0] = some_value;
args[1] = some_other_value;
// Do something with args (e.g. call jl_... functions)
JL_GC_POP();</code></pre><p>Reference: <a href="https://docs.julialang.org/en/v1/manual/embedding/index.html">Embedding Julia</a></p><h2><a class="nav-anchor" id="Quick-Reference-for-Implementing-C-Custom-Operators-in-ADCME-1" href="#Quick-Reference-for-Implementing-C-Custom-Operators-in-ADCME-1">Quick Reference for Implementing C++ Custom Operators in ADCME</a></h2><ol><li>Set output shape</li></ol><pre><code class="language-none">c-&gt;set_output(0, c-&gt;Vector(n));
c-&gt;set_output(0, c-&gt;Matrix(m, n));
c-&gt;set_output(0, c-&gt;Scalar());</code></pre><ol><li>Names</li></ol><p><code>.Input</code> and <code>.Ouput</code> : names must be in lower case, no <code>_</code>, only letters.</p><ol><li>TensorFlow Input/Output to TensorFlow Tensors</li></ol><pre><code class="language-none">grad.vec&lt;double&gt;();
grad.scalar&lt;double&gt;();
grad.matrix&lt;double&gt;();
grad.flat&lt;double&gt;();</code></pre><p>Obtain flat arrays</p><pre><code class="language-none">grad.flat&lt;double&gt;().data()</code></pre><ol><li>Scalars</li></ol><p>Allocate scalars using TensorShape()</p><ol><li>Allocate Shapes</li></ol><p>Although you can use -1 for shape reference, you must allocate exact shapes in <code>Compute</code></p><footer><hr/></footer></article></body></html>
